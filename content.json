{"meta":{"title":"Duan","subtitle":"游刃有余","description":"游刃有余","author":"小段","url":"http://duanyushuai.github.io","root":"/"},"pages":[{"title":"友情链接","date":"2022-06-12T06:28:38.126Z","updated":"2022-06-12T03:50:30.584Z","comments":true,"path":"links/index.html","permalink":"http://duanyushuai.github.io/links/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-11-03T09:16:25.884Z","updated":"2022-11-03T09:16:25.884Z","comments":false,"path":"about/index.html","permalink":"http://duanyushuai.github.io/about/index.html","excerpt":"","text":"个人详细介绍 河北 石家庄 毕业 浙江理工大学 本硕 在有限的时间里，做些有意义的事情 Reading for the rise of the ShiJiaZhuang"},{"title":"分类","date":"2022-06-13T02:45:28.915Z","updated":"2022-06-13T02:45:28.915Z","comments":false,"path":"categories/index.html","permalink":"http://duanyushuai.github.io/categories/index.html","excerpt":"","text":"title: CompletableFuturelayout: javacomments :false"},{"title":"书单","date":"2022-06-12T06:25:36.580Z","updated":"2022-06-12T03:50:30.584Z","comments":false,"path":"books/index.html","permalink":"http://duanyushuai.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-06-12T06:28:38.138Z","updated":"2022-06-12T03:50:30.584Z","comments":false,"path":"repository/index.html","permalink":"http://duanyushuai.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-06-13T03:01:27.694Z","updated":"2022-06-12T06:24:49.702Z","comments":false,"path":"tags/index.html","permalink":"http://duanyushuai.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"垃圾回收器","slug":"垃圾回收器","date":"2023-10-18T02:00:00.000Z","updated":"2023-04-21T10:22:45.951Z","comments":true,"path":"2023/10/18/垃圾回收器/","link":"","permalink":"http://duanyushuai.github.io/2023/10/18/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/","excerpt":"","text":"垃圾回收器i++和++i的区别 12345int i = 10;i++;//++i；sout(i)//字节码是一样的 1234int i = 10;i = i++;sout(i)//输出是10 str区别 12345678@Test public void test6()&#123; String str = new String(&quot;hello&quot;) + new String(&quot;world&quot;); // str.intern(); String str1 = &quot;helloworld&quot;; System.out.println(str == str1);//false --&gt; true (加上intern() 在str声明之前) &#125; 强引用、软引用、弱引用、虚引用软引用对应的类为 java.lang.ref.SoftReference, 一个软引用中的对象，不会很快被JVM回收，JVM会根据当前堆的使用情况来判断何时回收，当堆的使用率超过阈值时，才回去回收软引用中的对象。 弱引用中的对象具有很短的声明周期，因为在系统GC时，只要发现弱引用，不管堆空间是否足够，都会将对象进行回收。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 虚引用 就是 形同虚设 ，它并不能决定 对象的生命周期。任何时候这个只有虚引用的对象都有可能被回收。因此，虚引用主要用来跟踪对象的回收，清理被销毁对象的相关资源。 GC评估指标 吞吐量 吞吐量 &#x3D; 用户运行代码的时间&#x2F;用户运行代码的时间+垃圾运行的时间 90% 垃圾收集开销 吞吐量补数 10% 暂停时间 stop the world 收集频率 内存占用 java堆所占的空间 快速 主要抓住两点 吞吐量和暂停时间 使用GC1-XX:+UseG1GC Serial GC 1-XX:+UseSerialGC 年轻代 复制算法 老年代 标记整理算法 ParNew GC 12-XX:+UseParNewGC-XX:parallelGCThreas 限制线程数量，默认开启和CPU数据相同的线程数 CMS 老年代回收 初始标记（STW）：暂停时间非常短，标记与GC ROOT 直接关联的对象 并发标记：从GC ROOT 开始遍历整个对象图的过程 重新标记（STW）：修复并发标记环节，因为用户线程执行，导致数据的不一致问题 并发清除（耗时）：清除对象 优点 并发收集 和 低延迟 缺点 产生内存碎片 CPU敏感 产生浮动垃圾 G1 分成若干个区域 region之间是复制算法，整体看是标记压缩 GC日志","categories":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/categories/JVM%E8%B0%83%E4%BC%98/"}],"tags":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/tags/JVM%E8%B0%83%E4%BC%98/"}]},{"title":"面试知识","slug":"面试经验","date":"2023-05-24T08:07:47.377Z","updated":"2023-06-05T01:41:42.132Z","comments":true,"path":"2023/05/24/面试经验/","link":"","permalink":"http://duanyushuai.github.io/2023/05/24/%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C/","excerpt":"","text":"[toc] Mysql1. 聚簇索引和普通索引区别​ 聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。 在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找。 2. 如果聚簇索引的数据更新，它的存储要不要变化​ 聚族索引使用一般适用自增id，聚簇索引的数据的物理存放顺序是索引顺序是一致的，即使：只要索引是相邻的，那么对应的数据一定也是相邻的存储在物理磁盘上的。如果主键不是自增ID，那么可以想象，它会干些什么，不断地调整数据的物理地址，分页，当然也有一些措施来减少这些操作，但是却无法彻底避免。但是，如果是自增的，那就简单了，它只需要一页一页的写，索引结构相对紧凑，磁盘碎片少，效率也高。 ​ 因此MyISAM的主索引并非聚簇索引，那么它的物理地址必然是凌乱的，拿到这些物理地址，按照合适的ID算法进行读取，于是开始不同的不停的旋转。聚簇索引则只需一次I&#x2F;O。 3.事务隔离级别为Read uncommitted 、Read committed 、Repeatable read 、Serializable 。 ACID Atomicity Consistency Isolation Durability **什么是幻读 ** T1时刻 读取年龄为20的数据， Session1拿到了2条记录。 T2时刻 另一个进程Session2插入了一条新的记录，年龄也为20 T3时刻，Session1再次读取年龄为20的数据，发现还是2条数据，貌似 Session2新插入的数据并未影响到Session1的事务读取。 对于T1 – T3 时刻的情形，从结果来看，在可重复度读隔离级别下似乎解决了幻读的问题。 T4时刻，Session1 修改年龄为20的数据， 发现影响行数为3条。 为什么T3时候只能查到2条数据，但现在修改确修改了3条数据？ T5时刻，Session1 再次读取年龄为20的数据，发现结果变成了3条,我们知道被修改的第三条就是Session2在T2时刻新增的一条。 T4,T5 的结果来看，Session1 读到了 Session2 新插入的数据。产生了幻读现象 ​ 了解过MVCC的同学，肯定知道或听说过当前读，和快照读。（不知道的同学，可以查找相关资料了解下，当然后续我也会有文章专门介绍MVCC)。首先要知道的是MVCC 就InnoDB 秒级建立数据快照的能力。 快照读就是读取数据的时候会根据一定规则读取事务可见版本的数据。 而当前读就是读取最新版本的数据。什么情况下使用的是快照读：（快照读，不会加锁） 一般的 select * from …. where … 语句都是快照读 什么情况下使用的是当前读：（当前读，会在搜索的时候加锁） select * from …. where … for update select * from …. where … lock in share mode update …. set .. where … delete from. . where .. 如果事务中都使用快照读，那么就不会产生幻读现象，但是快照读和当前读混用就会产生幻读。 redis1. 缓存如果实现强一致性，不能使用缓存，我们说的这个，只是说降低概率发生，而不能完全的避免。 延时双删策略 在写库前后都进行 Redis 的删除操作，并且第二次删除通过延迟的方式进行 那么应该是什么样子的实现逻辑呢？ 第一步：先删除缓存 第二步：再写入数据库 第三步：休眠xxx毫秒（根据具体的业务时间来定） 第四步：再次删除缓存。 保证缓存和数据最终一致性 **利用cannal订阅 实现 redis和mysql的数据一致性 ** 利用mysql的binlog日志，比延时双删策略要好 2. 分布式锁限流 setNX 12345678127.0.0.1:6379&gt; SETNX test &#x27;try&#x27;(integer) 1127.0.0.1:6379&gt; get test&quot;try&quot;127.0.0.1:6379&gt; SETNX test &#x27;tryAgain&#x27;(integer) 0127.0.0.1:6379&gt; get test&quot;try&quot; 3. redis慢了怎么排查首先看基准运行速度，和配置相同，两台机器差值2倍以上，则是redis慢了 查看redis是否使用复杂命令，Redis 提供了慢日志命令的统计功能，它记录了有哪些命令在执行时耗时比较久。 可设置阈值 1234# 命令执行耗时超过 5 毫秒，记录慢日志CONFIG SET slowlog-log-slower-than 5000# 只保留最近 500 条慢日志CONFIG SET slowlog-max-len 500 如果你的应用程序执行的 Redis 命令有以下特点，那么有可能会导致操作延迟变大： 经常使用 O(N) 以上复杂度的命令，例如 SORT、SUNION、ZUNIONSTORE 聚合类命令 (建议放在客户端做) 使用 O(N) 复杂度的命令，但 N 的值非常大（分批次执行） 业务避免写入bigkey JAVA基础知识1. volatile和synchronized的区别， 问的比较细Volatile 实现共享变量的可见性 synchronized 还实现了原子性 获得互斥锁 清空工作内存 从主内存拷贝变量的最新副本到工作的内存 执行代码 将更改后的共享变量的值刷新到主内存 释放互斥锁 区别 volatile不需要加锁，比synchronized更轻量级，不会阻塞线程； 从内存可见性角度，volatile读相当于加锁，volatile写相当于解锁； synchronized既能够保证可见性，又能保证原子性，而volatile只能保证可见性，无法保证原子性。 2.线程池参数核心线程数、最大线程数、空闲线程存活时间、时间单位、等待队列、拒绝策略、线程工厂 3. 线程安全容器有哪些HashTableConcurrentHashMap:分段ArrayBlockingQueue：基于数组的有界阻塞队列 LinkedBlockingQueue：基于链表的有界阻塞队列。 Spring1. Spring容器中的Bean是否线程安全容器本身并没有提供Bean的线程安全策略，因此可以说Spring容器中的Bean本身不具备线程安全的特性，但是具体还是要结合具体scope的Bean去研究。无状态的单例线程安全。 https://repo.trojan-cdn.com/browser/spectre-whitelist.conf","categories":[{"name":"面试","slug":"面试","permalink":"http://duanyushuai.github.io/categories/%E9%9D%A2%E8%AF%95/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://duanyushuai.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"学习任务","slug":"学习任务","date":"2023-05-22T02:34:27.067Z","updated":"2023-06-05T01:38:58.125Z","comments":true,"path":"2023/05/22/学习任务/","link":"","permalink":"http://duanyushuai.github.io/2023/05/22/%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/","excerpt":"","text":"学习任务 学习项目 是否学习 掌握情况 rabbitMQ 是 2023&#x2F;5&#x2F;22已忘 kafka jvm调优 mysql的索引 Spring boot Spring cloud docker","categories":[],"tags":[]},{"title":"nacos","slug":"nacos","date":"2023-04-22T09:56:04.485Z","updated":"2023-04-22T09:57:19.000Z","comments":true,"path":"2023/04/22/nacos/","link":"","permalink":"http://duanyushuai.github.io/2023/04/22/nacos/","excerpt":"","text":"nacos","categories":[],"tags":[]},{"title":"sharding sphere","slug":"分库分表","date":"2023-04-05T02:00:00.000Z","updated":"2023-04-05T13:29:47.199Z","comments":true,"path":"2023/04/05/分库分表/","link":"","permalink":"http://duanyushuai.github.io/2023/04/05/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/","excerpt":"","text":"sharding sphere分库分表应用和问题 数据库设计师考虑垂直分裤，垂直分表 随着数据库数据量的增加，不要马上考虑水平切分，首先考虑缓存，读写分离，建立索引。 连接问题（分页和排序） 多数据源管理问题","categories":[{"name":"数据库","slug":"数据库","permalink":"http://duanyushuai.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://duanyushuai.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"JVM调优示例","slug":"jvm优化","date":"2023-03-30T02:00:00.000Z","updated":"2023-04-21T10:19:27.569Z","comments":true,"path":"2023/03/30/jvm优化/","link":"","permalink":"http://duanyushuai.github.io/2023/03/30/jvm%E4%BC%98%E5%8C%96/","excerpt":"","text":"JVM调优示例堆溢出参数 123-XX:+PrintGCDetails -XX:MetaspaceSize=64m-XX:HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapDump.hprof-XX:+PrintGCDateStamps -Xms200M -Xmx200M -Xloggx:log/gc-oomHeap.log 12345678@RequestMapping(&quot;/add&quot;) public void addObject()&#123; System.err.println(&quot;add&quot;+peopleSevice); ArrayList&lt;People&gt; people = new ArrayList&lt;&gt;(); while (true)&#123; people.add(new People()); &#125; &#125; gceasy可以分析GC日志 用工具分析dump文件 （jvisualvm） 元空间溢出常量池和对类型的卸载 1234567891011121314151617181920RequestMapping(&quot;/metaSpaceOom&quot;) public void metaSpaceOom()&#123; ClassLoadingMXBean classLoadingMXBean = ManagementFactory.getClassLoadingMXBean(); while (true)&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(People.class);// enhancer.setUseCache(false); enhancer.setUseCache(true); enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) -&gt; &#123; System.out.println(&quot;我是加强类，输出print之前的加强方法&quot;); return methodProxy.invokeSuper(o,objects); &#125;); People people = (People)enhancer.create(); people.print(); System.out.println(people.getClass()); System.out.println(&quot;totalClass:&quot; + classLoadingMXBean.getTotalLoadedClassCount()); System.out.println(&quot;activeClass:&quot; + classLoadingMXBean.getLoadedClassCount()); System.out.println(&quot;unloadedClass:&quot; + classLoadingMXBean.getUnloadedClassCount()); &#125; &#125; GC overhead limit exceeded1234567891011121314151617181920212223242526272829public static void test1() &#123; int i = 0; List&lt;String&gt; list = new ArrayList&lt;&gt;(); try &#123; while (true) &#123; list.add(UUID.randomUUID().toString().intern()); i++; &#125; &#125; catch (Throwable e) &#123; System.out.println(&quot;************i: &quot; + i); e.printStackTrace(); throw e; &#125; &#125; public static void test2() &#123; String str = &quot;&quot;; Integer i = 1; try &#123; while (true) &#123; i++; str += UUID.randomUUID(); &#125; &#125; catch (Throwable e) &#123; System.out.println(&quot;************i: &quot; + i); e.printStackTrace(); throw e; &#125; &#125; JDK6 新加的错误类型，一般是堆太小导致的。 98% 的时间用来做GC 回收不到2% 的内存，抛出异常 解决办法 1、有死循环，或者占大内存，优化代码 2、dump内存，检查时候有内存泄漏，加大内存 线程溢出很少遇到，调小线程栈大小 JMeter 测试多线程 Tomcat 配置参数 1vim catalina.sh 1.调整堆大小，提高吞吐量1-Xmx1024m -Xms1024m 2.JIT编译 栈上分配123-XX:-DoEscpeAnalysis //去掉逃逸分析， 默认是开启的//堆对象没有对外暴露，就在栈上分配//将堆内存转为栈分配，一个对象没有逃逸出方法 3. 合理配置堆内存分配过大，fullGC时间就会长，分配小的话，频繁fullGC 推荐设置 名称 命令 推荐设置 Java heap -Xms and -Xmx fullGC运行多次之后，看看剩余大小，在它3-4倍之间 元空间 -XX:PermSize -XX:MaxPermSize 1.2倍到1.5倍之间 新生代 -Xmn 1-1.5 老年代 2-3 4.CPU过高排查方案1234ps aux | grep java 查看当前java进程使用的cpu、内存和磁盘情况获取使用异常的进程top -Hp 进程pid 检查丹铅使用异常的线程pid把线程pid 换成16进制 31695-&gt;7bcf 得到0X7bcjstack 进程pid ｜ grep -A20 0X7bcf 5.G1并发GC线程数对性能的影响参数 123456-XX: +UserG1GC 手动指定使用G1回收器-XX:G1HeapRegionSize 设置每个Region大小，值是2次幂，目标根据最小的堆划分出2048个区域，默认是堆内存1/2000-XX:MaxGCPauseMillis 设置期望达到最大的GC停顿时间指标。默认是200ms-XX:ParallelGCThread 设置stw的GC线程数的值，最多8-XX:ConcGCThreads 设置并发编辑的线程数，将n设置为ParallelGCThread的 1/4-XX:InitiatingHeapOccupancyPercent 设置出发并发GC周期的java堆占用率值，超过此值就出发GC，默认45 -XX:ConcGCThreads 影响吞吐量大小，建议设置1&#x2F;4 6. 日均百万订单JVM参数日均百万订单 -&gt; 4小时产生-》 300w&#x2F;4&#x2F;3600 &#x3D; 208单&#x2F;s 按300单&#x2F;s 三台机器， 每台机器100单&#x2F;s 每台机器 4核8G 每单产生2MB对象 ，假设分给堆4G 新生代1333MB 1333M&#x2F;2M&#x2F;60 &#x3D; 11.1分钟发生一次minorGC 因为是订单业务，可以提升新生代，进一步降低GC频率，进入老年代对象会降低，减少FUlLGC频率 业务量暴增 ，增加机器， 面试题 下载文件之前是1.5G堆空间，后来换了16G更慢了 FullGC时间更长 咋办 更改垃圾回收器 parallel GC ; ParNew CMS G1 配置GC参数 -XX:MaxGCPauseMillis 、-XX:ConcGCThreads 根据log日志和dump文件分析 ，空间占比的关系 1jstat jinfo jstack jmap arthas可以学一下","categories":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/categories/JVM%E8%B0%83%E4%BC%98/"}],"tags":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/tags/JVM%E8%B0%83%E4%BC%98/"}]},{"title":"msyql索引","slug":"mysql索引","date":"2023-03-29T02:00:00.000Z","updated":"2023-03-30T01:14:58.988Z","comments":true,"path":"2023/03/29/mysql索引/","link":"","permalink":"http://duanyushuai.github.io/2023/03/29/mysql%E7%B4%A2%E5%BC%95/","excerpt":"","text":"mysql 索引Study from https://juejin.cn/post/7147609139974242317#heading-13 按功能逻辑层次划分 普通索引、唯一索引、主键索引、全文索引、空间索引 索引创建方式唯一索引创建12345678910111213-- 方式①CREATE UNIQUE INDEX indexName ON tableName (columnName(length));-- 方式②ALTER TABLE tableName ADD UNIQUE INDEX indexName(columnName);-- 方式③CREATE TABLE tableName( columnName1 INT(8) NOT NULL, columnName2 ...., ....., UNIQUE INDEX [indexName] (columnName(length)) ); 主键索引创建12345678910-- 方式①ALTER TABLE tableName ADD PRIMARY KEY indexName(columnName);-- 方式②CREATE TABLE tableName( columnName1 INT(8) NOT NULL, columnName2 ...., ....., PRIMARY KEY [indexName] (columnName(length)) ); 全文索引创建123456-- 方式①ALTER TABLE tableName ADD FULLTEXT INDEX indexName(columnName);-- 方式②CREATE FULLTEXT INDEX indexName ON tableName(columnName); 不过在创建全文索引时，有三个注意点： 5.6版本的MySQL中，存储引擎必须为MyISAM才能创建。 创建全文索引的字段，其类型必须要为CHAR、VARCHAR、TEXT等文本类型。 如果想要创建出的全文索引支持中文，需要在最后指定解析器：with parser ngram。 此时还依旧是以文章表为例，为文章名称字段创建一个全文索引，命令如下： 12345ALTER TABLE zz_article ADD FULLTEXT INDEX ft_article_name(article_name) WITH PARSER NGRAM; 123456789101112131415161718192021222324+------------+--------------------------+-------------------+| article_id | article_name | special_column |+------------+--------------------------+-------------------+| 1 | MySQL架构篇：....... | 《全解MySQL》 || 2 | MySQL执行篇：....... | 《全解MySQL》 || 3 | MySQL设计篇：....... | 《全解MySQL》 || 4 | MySQL索引篇：....... | 《全解MySQL》 |+------------+--------------------------+-------------------+SELECT COUNT(article_id) AS &#x27;搜索结果数量&#x27; FROM `zz_article` WHERE MATCH(article_name) AGAINST(&#x27;MySQL&#x27;);-- 运行结果如下：+--------------+| 搜索结果数量 |+--------------+| 4 |+--------------+ 联合索引1234CREATE INDEX indexName ON tableName (column1(length),column2...);ALTER TABLE tableName ADD INDEX indexName(column1(length),column2...); 使用索引正确姿势1234567891011121314151、查询`SQL`中尽量不要使用`OR`关键字，可以使用多`SQL`或子查询代替。2、模糊查询尽量不要以`%`开头，如果实在要实现这个功能可以建立全文索引。3、编写`SQL`时一定要注意字段的数据类型，否则`MySQL`的隐式转换会导致索引失效。4、一定不要在编写`SQL`时让索引字段执行计算工作，尽量将计算工作放在客户端中完成。5、对于索引字段尽量不要使用计算类函数，一定要使用时请记得将函数计算放在`=`后面。6、多条件的查询`SQL`一定要使用联合索引中的第一个字段，否则会打破最左匹配原则。7、对于需要对比多个字段的查询业务时，可以拆分为连表查询，使用临时表代替。8、在`SQL`中不要使用反范围性的查询条件，大部分反范围性、不等性查询都会让索引失效。 1.索引覆盖2.索引下推3.MRR机制而MRR机制就主要是解决这个问题的，针对于辅助索引的回表查询，减少离散IO，并且将随机IO转换为顺序IO，从而提高查询效率。 1SET @@optimizer_switch=&#x27;mrr=on|off,mrr_cost_based=on|off&#x27;; 索引过程局部性原理​ 局部性原理的思想比较简单，比如目前有三块内存页x、y、z是相连的，CPU此刻在操作x页中的数据，那按照计算机的特性，一般同一个数据都会放入到物理相连的内存地址上存储，也就是当前在操作x页的数据，那么对于y，z这两页内存的数据也很有可能在接下来的时间内被操作，因此对于y，z这两页数据则会提前将其载入到高速缓冲区（L1/L2/L3），这个过程叫做利用局部性原理“预读”数据","categories":[{"name":"索引","slug":"索引","permalink":"http://duanyushuai.github.io/categories/%E7%B4%A2%E5%BC%95/"}],"tags":[{"name":"索引","slug":"索引","permalink":"http://duanyushuai.github.io/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"java各种变量","slug":"java各种环境变量","date":"2023-03-02T02:00:00.000Z","updated":"2023-03-03T01:17:19.387Z","comments":true,"path":"2023/03/02/java各种环境变量/","link":"","permalink":"http://duanyushuai.github.io/2023/03/02/java%E5%90%84%E7%A7%8D%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"java各种变量java -jar 配置参数写法说明123java -Dxxx=test -jar xxx.jar （放在-jar之前）取值： System.getProperty(&quot;xxx&quot;) spring的@value(&quot;$&#123;xxx&#125;&quot;) 12java -jar xxx.jar value1=1 value2=2 （放在启动jar包之后）参数就是jar包里主启动类中main方法的args参数，按顺序来 1234SpringBoot项目写法 java -jar xxx.jar --xxx=test（放在启动jar包之后）取值：spring的@value(&quot;$&#123;xxx&#125;&quot;)","categories":[{"name":"java各种变量","slug":"java各种变量","permalink":"http://duanyushuai.github.io/categories/java%E5%90%84%E7%A7%8D%E5%8F%98%E9%87%8F/"}],"tags":[{"name":"java各种变量","slug":"java各种变量","permalink":"http://duanyushuai.github.io/tags/java%E5%90%84%E7%A7%8D%E5%8F%98%E9%87%8F/"}]},{"title":"dockerfile 编写","slug":"dockerfile编写","date":"2023-03-01T03:00:23.000Z","updated":"2023-03-03T07:14:45.118Z","comments":true,"path":"2023/03/01/dockerfile编写/","link":"","permalink":"http://duanyushuai.github.io/2023/03/01/dockerfile%E7%BC%96%E5%86%99/","excerpt":"","text":"dockerfile 编写12345678910FROM alpineLABEL maintainer=&#x27;duanyushuai&#x27; \\adv=dev\\aab=fff#运行的命令，安装了软件，修改了文件，默认用id=0 也就是root#镜像构建运行的命令RUN echo 111CMD ping baidu.com 123456RUN 命令# shell 形式 bash -c &quot;echo 111&quot;RUN echo 1111RUN [&quot;echo&quot;,&quot;2222&quot;] ARG 和 ENV12345678910# 指定构建参数有效ARG aaa =aaa# 指定环境变量[为RUN以及CMD指定环境变量的]ENV parm=1111 1RUN echo $parmRUN [&quot;echo&quot;,&quot;$parm&quot;]CMD sleep 10; echo $parm 12345678910111213141516171819202122232425262728ARG version=1.3.0FROM alpine:$version#可以用命令替换参数docker build --no-cache --build-arg version=&quot;1.55.4&quot; -t [镜像名]：[镜像版本] -f dockerfile .ENV app=duan#构建期和运行期都可以生效，但只能在运行期修改docker run -e app=haha ENV 的坑ENV msg1=helloENV msg2=$&#123;msg1&#125;echo $&#123;msg1&#125;echo $&#123;msg2&#125;CMD [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;echo $&#123;msg1&#125;;echo $&#123;msg2&#125;&quot;]docker run -it e msg1=666 #输出的是666 hello #原因是docker build 的时候，env的指已经写好了 msg1=hello。msg2 = hello ADD 和COPY123456789101112131415# 把上下文的内容复制到镜像中，如果是压缩包自动解压，如果是远程自动下载#自动下载ADD https://download.redis.io/releases/redis-6.2.1.tar.gz /dest/ #不加最后斜杠变为dest文件#RUN指令并没有上下文关系 不能RUN cd /dest RUN ls -lRUN cd /dest &amp;&amp; ls -l#宿主机到镜像 自动解压 ADD *.tar.gz /app/ 不自动解压COPY WORKDIR 和VOLUME12345678910111213141516171819202122232425262728 # 为一下所有的命令运行指定了基础目录 WORKDIR /app WORKDIR abc 可以嵌套 # pwd &amp;&amp; ls -l RUN pwd &amp;&amp; ls -l #----------------------------- #挂载容器内文件 ，没有就创建 #指定了VOLUME，即使启动容器没有指定 -v 参数，我们也会自动进行匿名卷挂载 VOLUM [&quot;/hello&quot;,&quot;/app&quot;] RUN mkdir /hello &amp;&amp; mkdir /appRUN echo 111 &gt; /hello/a.txtRUN echo 222 &gt; /app/b.txt#挂载之后# 1）但是docker commit 提交当前容器的所有变化为镜像的时候，就会丢弃# 2）VOLUME [&quot;/hello&quot;,&quot;/app&quot;] 容器以后自动挂载，在dockerfile中对VOLUME的所有修改都不生效# 3）建议VOLUME 写在最后面VOUME [&quot;/hello&quot;,&quot;/app&quot;]# 这两句话没有生效RUN echo 4444 &gt;&gt; /hello/a.txtRUN echo 4444 &gt;&gt; /app/b.txt EXPOSE123#暴露，只是一个声明，给程序员看的# 给docker 看的 -d -P（随机分配端口）EXPOSE 8080 CMD 和 ENTRYPOINT1234567# 统一是容器启动命令#官方推荐写法，变化的写CMD，而CMD提供的参数给ENTRPOINT使用的# docker run imageName cmd1 一旦传递了cmd1，CMD指定的所有参数都会被覆盖。#自定义参数一定要写全CMD [&quot;5&quot;,&quot;baidu.com&quot;]ENTRYPOINT [&quot;ping&quot;,&quot;-c&quot;] 多阶段构建1234567891011121314151617181920FROM maven:3.5.0-jdk-8-alpine AS builderWORKDIR /appadd ./ /appRUN mvn clean package -Dmaven.test.skip=true# 第二阶段，最小运行环境只需要jreFROM openjdk:8-jre-alpine# 修改时区 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneLABEL maintainer = &quot;duanyushuai&quot;#从上一个阶段复制内容COPY --frombuilder /app/target/*.jar /app/jar#docker run -e JAVA_OPTS=&quot;-Xmx512m -Xms33 &quot; -e PARAM=&quot;--spring.profiles=dev&quot; -jar app.jarENV JAVA_OPTS=&quot;&quot;ENV PARAMS=&quot;&quot;ENTRYPOINT [&quot;sh&quot;,&quot;-c&quot;,&quot;java -Djava.security.egd=file:/dev/./urandom $JAVA_OPTS -jar /app.jar $PARAMS&quot;] springboot dockerfile常用写法1234567891011121314FROM openjdk:8-jre-aalpineLABEL maintainer=&quot;duanyushuai&quot;COPY target/*.jar /app.jarRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezone &amp;&amp; touch /app.jarENV JAVA_OPTS=&quot;&quot;ENV PARAMS=&quot;&quot;ENTRYPOINT [&quot;sh&quot;,&quot;-c&quot;,&quot;java -Djava.security.egd=file:/dev/./urandom $JAVA_OPTS -jar /app.jar $PARAMS&quot;]","categories":[{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/tags/docker/"}]},{"title":"msyql性能优化","slug":"mysql优化","date":"2023-03-01T02:00:00.000Z","updated":"2023-03-31T07:35:51.971Z","comments":true,"path":"2023/03/01/mysql优化/","link":"","permalink":"http://duanyushuai.github.io/2023/03/01/mysql%E4%BC%98%E5%8C%96/","excerpt":"","text":"msyql性能优化1.系统配置优化1.1 内存读取数据1调大 innodb_buffer_pool_size 1.2 数据预热默认情况，仅仅有某条数据被读取一次，才会缓存在 innodb_buffer_pool。所以，数据库刚刚启动，须要进行数据预热，将磁盘上的全部数据缓存到内存中。数据预热能够提高读取速度。 1.3降低磁盘写入1.增大redolog，减少落盘次数 innodb_log_file_size 设置为 0.25 * innodb_buffer_pool_size 2.通用查询日志、慢查询日志可以不开 ，bin-log开 生产中不开通用查询日志，遇到性能问题开慢查询日志 2. 表结构优化2.1 设计中间表2.2 设计冗余字段2.3拆表对于表中经常不被使用的字段或者存储数据比较多的字段，考虑拆表 2.5 字段的设计字段宽度尽可能小，尽量把字段设置为NOTNULL，能用数字的用数值类型 3. sql语句，索引优化3.1 EXPLAIN 查看索引使用情况3.2 SQL语句中 IN 包含的值不应过多3.3 SELECT 语句务必指明字段名称3.4 当只需要一条数据的时候，使用 limit 13.5 排序字段加索引3.6 不使用ORDER BY RAND()3.7 如果限制条件中其他字段没有索引，尽量少用 or3.8 区分in 和exists、not in和not exists区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为 驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合 于外表小而内表大的情况。 12select * from tbiguser limit 9999998, 2;select * from tbiguser where id&gt;9999998 limit 2; 3.9不建议使用%前缀模糊查询3.10避免在where子句中对字段进行表达式操作3.11避免隐式类型转换3.12对于联合索引来说，要遵守最左前缀法则3.13 使用JOIN 优化，尽量选择少表作为驱动表4.explain使用123456----+-------------+----------+------+---------------+------+---------+------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------+------+---------------+------+---------+------+------+-------+| 1 | SIMPLE | zz_users | ALL | NULL | NULL | NULL | NULL | 3 | |+----+-------------+----------+------+---------------+------+---------+------+------+-------+ id：这是执行计划的ID值，这个值越大，表示执行的优先级越高。 select_type：当前查询语句的类型，有如下几个值： simple：简单查询。 primary：复杂查询的外层查询。 subquery：包含在查询语句中的子查询。 derived：包含在FROM中的子查询。 table：表示当前这个执行计划是基于那张表执行的。 type：当前执行计划查询的类型，有几种情况： all：表示走了全表查询，未命中索引或索引失效。 system：表示要查询的表中仅有一条数据。 const：表示当前SQL语句的查询条件中，可以命中索引查询。 range：表示当前查询操作是查某个区间。 eq_ref：表示目前在做多表关联查询。 ref：表示目前使用了普通索引查询。 index：表示目前SQL使用了辅助索引查询。 possible_keys：执行SQL时，优化器可能会选择的索引（最后执行不一定用）。 key：查询语句执行时，用到的索引名字。 key_len：这里表示索引字段使用的字节数。 ref：这里显示使用了那种查询的类型。 rows：当前查询语句可能会扫描多少行数据才能检索出结果。 Extra：这里是记录着额外的一些索引使用信息，有几种状态： using index：表示目前使用了覆盖索引查询（稍后讲）。 using where：表示使用了where子句查询，通常表示没使用索引。 using index condition：表示查询条件使用到了联合索引的前面几个字段。 using temporary：表示使用了临时表处理查询结果。 using filesort：表示以索引字段之外的方式进行排序，效率较低。 select tables optimized away：表示在索引字段上使用了聚合函数。 123456789create table tbiguser( id int primary key auto_increment, nickname varchar(255), loginname varchar(255), age int, sex char(1), status int, address varchar(255)); 1create table tuser2( id int primary key auto_increment, name varchar(255), address varchar(255) ); 1.无变化12345678910111213141516171819EXPLAIN SELECT count( id ) num, address FROM tbiguser WHERE address IN ( SELECT DISTINCT address FROM tuser1 ) GROUP BY address UNIONSELECT count( id ) num, address FROM tbiguser WHERE address IN ( SELECT DISTINCT address FROM tuser2 ) GROUP BY address 1232 dongbei1 xianggang1 shanghai 2. 给address加索引123alter table tbiguser add index idx_addr(address);alter table tuser1 add index idx_addr(address); alter table tuser2 add index idx_addr(address); 3. 修改sql123456789101112EXPLAIN SELECT count( id ) num, address FROM tbiguser WHERE address IN ( SELECT DISTINCT address FROM tuser1 ) OR address IN ( SELECT DISTINCT address FROM tuser2 ) GROUP BY address ORDER BY address; 4. 从前面的执行计划可以看出，索引只是使用了覆盖索引，rows&#x3D;9754360， 说明还是几乎扫描了全表的 行 利用address索引，先过滤数据 12select distinct b.* from tuser2 a,tbiguser b where a.address=b.address;select distinct b.* from tuser1 a,tbiguser b where a.address=b.address; 创建视图 123create view v_tuser as select distinct b.* from tuser1 a,tbiguser b where a.address=b.address union all select distinct b.* from tuser2 a,tbiguser b where a.address=b.address;--执行SQL select count(id) cont ,address from v_tuser group by address order by address; 优化总结开启慢查询日志，定位运行慢的SQL语句 利用explain执行计划，查看SQL执行情况 关注索引使用情况：type 关注Rows：行扫描 关注Extra：没有信息最好 加索引后，查看索引使用情况，index只是覆盖索引，并不算很好的使用索引 如果有关联尽量将索引用到eq_ref或ref级别 复杂SQL可以做成视图，视图在MySQL内部有优化，而且开发也比较友好 对于复杂的SQL要逐一分析，找到比较费时的SQL语句片段进行优化","categories":[{"name":"msyql","slug":"msyql","permalink":"http://duanyushuai.github.io/categories/msyql/"}],"tags":[{"name":"msyql","slug":"msyql","permalink":"http://duanyushuai.github.io/tags/msyql/"}]},{"title":"k8s","slug":"k8s","date":"2023-02-22T06:14:11.674Z","updated":"2023-04-24T13:35:29.952Z","comments":true,"path":"2023/02/22/k8s/","link":"","permalink":"http://duanyushuai.github.io/2023/02/22/k8s/","excerpt":"","text":"k8s1kubectl get pod","categories":[],"tags":[]},{"title":"常用linux命令","slug":"linux","date":"2023-02-10T01:50:08.054Z","updated":"2023-03-02T13:50:40.581Z","comments":true,"path":"2023/02/10/linux/","link":"","permalink":"http://duanyushuai.github.io/2023/02/10/linux/","excerpt":"","text":"查找文件名中包含某字符（如”elm”）的文件 1find /home/lijiajia/ -name &#x27;*elm*&#x27; 删除目录 1rm -rf /root/logs/game 删除文件夹 1rm -f /root/logs/game","categories":[],"tags":[]},{"title":"netty学习","slug":"netty笔记","date":"2023-01-30T13:33:46.509Z","updated":"2023-02-05T13:55:27.744Z","comments":true,"path":"2023/01/30/netty笔记/","link":"","permalink":"http://duanyushuai.github.io/2023/01/30/netty%E7%AC%94%E8%AE%B0/","excerpt":"","text":"netty 笔记零拷贝传统IO，从直接内存DMA 拷贝到内核 在用CPU拷贝到用户态进行修改，在用cpu拷贝内核，在DMA拷贝到协议栈 mmap优化 通过内存映射，用户空间可以共享内核空间数据。 零拷贝指没有cpu拷贝","categories":[],"tags":[]},{"title":"Ruoyi-pro 随记","slug":"若依框架学习","date":"2023-01-22T02:00:00.000Z","updated":"2023-04-25T09:29:20.824Z","comments":true,"path":"2023/01/22/若依框架学习/","link":"","permalink":"http://duanyushuai.github.io/2023/01/22/%E8%8B%A5%E4%BE%9D%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Ruoyi-pro 随记1.@Scheduled注解1@Scheduled(fixedDelay = 60*1000, initialDelay = 60*1000) fixedDelay: 它的间隔时间是根据上次的任务结束的时候开始计时的。比如一个方法上设置了fixedDelay&#x3D;5*1000，那么当该方法某一次执行结束后，开始计算时间，当时间达到60秒，就开始再次执行该方法。 initialDelay: 容器启动后60s执行一次 2. @EventListene 注解1@EventListener(ApplicationReadyEvent.class) 延伸 容器启动时候执行方法 @PostConstruct 存在的问题是如果执行的方法耗时过长，会导致项目在方法执行期间无法提供服务。 123456789101112@Componentpublic class StartInit &#123;//// @Autowired 可以注入bean// ISysUserService userService; @PostConstruct public void init() throws InterruptedException &#123; Thread.sleep(10*1000);//这里如果方法执行过长会导致项目一直无法提供服务 System.out.println(123456); &#125;&#125; ApplicationReadyEvent再注册一个 CommandLineRunner 类, 在这个 runner 类中将这个公共 int 值自增一次 再添加一个 ApplicationStartedEvent 事件的监听者，触发时打印出这个公共 int 值 再添加一个 ApplicationReadyEvent 事件的监听者，触发时打印出这个公共 int 值 运行这个 SpringBoot 程序，那么： ApplicationStartedEvent 事件的监听者打印出来的 int 值是 1 这个 CommandLineRunner 类看到的 int 值是 1，将其自增 1 ApplicationReadyEvent 事件的监听者打印出来的 int 值是 2 3. @Async注解创建一个线程执行 4.","categories":[{"name":"开源框架学习","slug":"开源框架学习","permalink":"http://duanyushuai.github.io/categories/%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"开源框架学习","slug":"开源框架学习","permalink":"http://duanyushuai.github.io/tags/%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"}]},{"title":"动态线程池","slug":"动态线程池","date":"2023-01-13T02:00:00.000Z","updated":"2023-03-01T02:12:27.913Z","comments":true,"path":"2023/01/13/动态线程池/","link":"","permalink":"http://duanyushuai.github.io/2023/01/13/%E5%8A%A8%E6%80%81%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"动态线程池https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html https://mp.weixin.qq.com/s/leoP_3uOtXsE55PMmSAVTg https://mp.weixin.qq.com/s/4kir2LfMnyuApKwulnRAmA","categories":[{"name":"线程","slug":"线程","permalink":"http://duanyushuai.github.io/categories/%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://duanyushuai.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"springboot源码","slug":"springboot源码","date":"2023-01-10T12:00:00.000Z","updated":"2023-01-11T08:39:23.484Z","comments":true,"path":"2023/01/10/springboot源码/","link":"","permalink":"http://duanyushuai.github.io/2023/01/10/springboot%E6%BA%90%E7%A0%81/","excerpt":"","text":"Springboot源码@springbootApplication注解包括 12345678910111213//@EnableAutoConfiguration@Configuration//@AutoConfigurationPackage@Import(&#123;Registrar.class&#125;)@Import(&#123;AutoConfigurationImportSelector.class&#125;)@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125; @Import(&#123;Registrar.class&#125;) 指定我们要扫描哪些包下组件 AutoConfigurationPackages怎么创建对象的，就是controller等对象创建 @Import(&#123;AutoConfigurationImportSelector.class&#125;) 中加载classLoader.getResources(&quot;META-INF/spring.factories&quot;) SPI机制 找到@EnableAutoConfiguration中全类名对应的值 有过滤组件，引入了包，自动配置才生效 Spring 启动器 springmvc启动器 1.首先先启动ServletWebServerFactoryAutoConfiguration servlet容器 2.在启动DispatcherServletAutoConfiguration 1. ServletWebServerFactoryAutoConfiguration@EnableConfigurationProperties(ServlerProperties.class) 配置tomcat参数 @Import WebServerFactoryCustomizerBeanPostProcessor 导入三种服务器 Tomcat 、jetty、Undertow 默认是Tomcat生效 给容器中放入TomcatServeletWebServerFactory @ConditionalOnMissingBean(ServletWebServerFactory) 我们也可以自己放一个ServletWebServerFactory TomcatServeletWebServerFactory 里的getWebServer 创建new Tomcat()","categories":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/categories/springboot/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://duanyushuai.github.io/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"caffeine 本地缓存","slug":"Caffeine本地缓存","date":"2023-01-10T06:00:00.000Z","updated":"2023-01-11T01:23:04.959Z","comments":true,"path":"2023/01/10/Caffeine本地缓存/","link":"","permalink":"http://duanyushuai.github.io/2023/01/10/Caffeine%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98/","excerpt":"","text":"caffeine 本地缓存12345&lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;version&gt;2.9.3&lt;/version&gt;&lt;/dependency&gt; 官方文档 ：https://github.com/ben-manes/caffeine/wiki/Eviction-zh-CN 添加 3种加载策略手动加载 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package duan.test.caffeine;import com.github.benmanes.caffeine.cache.Cache;import com.github.benmanes.caffeine.cache.Caffeine;import com.github.benmanes.caffeine.cache.LoadingCache;import lombok.extern.slf4j.Slf4j;import java.util.concurrent.TimeUnit;import java.util.function.Function;@Slf4jpublic class CaffeineTest2 &#123; public static void main(String[] args) &#123; // 初始化缓存，设置了1分钟的写过期，100的缓存最大个数 Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(); int key1 = 1; // 使用getIfPresent方法从缓存中获取值。如果缓存中不存指定的值，则方法将返回 null： System.out.println(cache.getIfPresent(key1)); // 也可以使用 get 方法获取值，该方法将一个参数为 key 的 Function 作为参数传入。如果缓存中不存在该 key // 则该函数将用于提供默认值，该值在计算后插入缓存中： System.out.println(cache.get(key1, new Function&lt;Integer, Integer&gt;() &#123; @Override public Integer apply(Integer integer) &#123; return 2; &#125; &#125;)); // 校验key1对应的value是否插入缓存中 System.out.println(cache.getIfPresent(key1)); // 手动put数据填充缓存中 int value1 = 2; cache.put(key1, value1); // 使用getIfPresent方法从缓存中获取值。如果缓存中不存指定的值，则方法将返回 null： System.out.println(cache.getIfPresent(1)); // 移除数据，让数据失效 cache.invalidate(1); System.out.println(cache.getIfPresent(1)); &#125;&#125; 同步加载数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package duan.test.caffeine;import com.github.benmanes.caffeine.cache.CacheLoader;import com.github.benmanes.caffeine.cache.Caffeine;import com.github.benmanes.caffeine.cache.LoadingCache;import org.checkerframework.checker.nullness.qual.NonNull;import org.checkerframework.checker.nullness.qual.Nullable;import java.util.Arrays;import java.util.Map;import java.util.concurrent.TimeUnit;public class CaffeineTest2 &#123; public static void main(String[] args) &#123; test(); &#125; /** * 模拟从数据库中读取key * * @param key * @return */ private static int getInDB(int key) &#123; return key + 1; &#125; public static void test() &#123; // 初始化缓存，设置了1分钟的写过期，100的缓存最大个数 LoadingCache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(new CacheLoader&lt;Integer, Integer&gt;() &#123; @Nullable @Override public Integer load(@NonNull Integer key) &#123; return getInDB(key); &#125; &#125;); int key1 = 1; // get数据，取不到则从数据库中读取相关数据，该值也会插入缓存中： Integer value1 = cache.get(key1); System.out.println(value1); // 支持直接get一组值，支持批量查找 Map&lt;Integer, Integer&gt; dataMap = cache.getAll(Arrays.asList(1, 2, 3)); System.out.println(dataMap); &#125; public static void test2() &#123; LoadingCache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(new CacheLoader&lt;Integer, Integer&gt;() &#123; @Nullable @Override public Integer load(@NonNull Integer key) &#123; return getInDB(key); &#125; &#125;); int key1 = 1; // get数据，取不到则从数据库中读取相关数据，该值也会插入缓存中： Integer value1 = cache.get(key1); System.out.println(value1); // 支持直接get一组值，支持批量查找 Map&lt;Integer, Integer&gt; dataMap = cache.getAll(Arrays.asList(1, 2, 3)); System.out.println(dataMap); &#125;&#125; **异步加载 ** 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package duan.test.caffeine;import com.github.benmanes.caffeine.cache.AsyncCache;import com.github.benmanes.caffeine.cache.Caffeine;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ExecutionException;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.function.Function;public class CaffeineTest2 &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; test(); &#125; /** * 模拟从数据库中读取key * * @param key * @return */ private static int getInDB(int key) &#123; return key + 1; &#125; public static void test() throws ExecutionException, InterruptedException &#123; // 使用executor设置线程池 AsyncCache&lt;Integer, Integer&gt; asyncCache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100).executor(Executors.newSingleThreadExecutor()).buildAsync(); Integer key = 1; // get返回的是CompletableFuture CompletableFuture&lt;Integer&gt; future = asyncCache.get(key, new Function&lt;Integer, Integer&gt;() &#123; @Override public Integer apply(Integer key) &#123; // 执行所在的线程不在是main，而是ForkJoinPool线程池提供的线程 System.out.println(&quot;当前所在线程：&quot; + Thread.currentThread().getName()); int value = getInDB(key); return value; &#125; &#125;); int value = future.get(); System.out.println(&quot;当前所在线程：&quot; + Thread.currentThread().getName()); System.out.println(value); &#125;&#125; 淘汰机制基于权重 1234567891011121314151617181920// 初始化缓存，设置最大权重为2 Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .maximumWeight(2) .weigher(new Weigher&lt;Integer, Integer&gt;() &#123; @Override public @NonNegative int weigh(@NonNull Integer key, @NonNull Integer value) &#123; return key; &#125; &#125;) .build(); cache.put(1, 1); // 打印缓存个数，结果为1 System.out.println(cache.estimatedSize()); cache.put(2, 2); // 稍微休眠一秒 Thread.sleep(1000); // 打印缓存个数，结果为1 System.out.println(cache.estimatedSize()); 基于大小 1234567891011121314// 初始化缓存，缓存最大个数为1 Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .maximumSize(1) .build(); cache.put(1, 1); // 打印缓存个数，结果为1 System.out.println(cache.estimatedSize()); cache.put(2, 2); // 稍微休眠一秒 Thread.sleep(1000); // 打印缓存个数，结果为1 System.out.println(cache.estimatedSize()); 基于时间 然后是基于时间的方式，基于时间的回收机制，Caffeine有提供了三种类型，可以分为： 访问后到期，时间节点从最近一次读或者写，也就是get或者put开始算起。 写入后到期，时间节点从写开始算起，也就是put。 自定义策略，自定义具体到期时间。 12345678910 // 设置写入5秒后数据到期Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterWrite(5, TimeUnit.SECONDS).scheduler(Scheduler.systemScheduler()) .build(); cache.put(1, 2); System.out.println(cache.getIfPresent(1)); Thread.sleep(6000); System.out.println(cache.getIfPresent(1)); 12345678910// 设置访问5秒后数据到期 Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterAccess(5, TimeUnit.SECONDS).scheduler(Scheduler.systemScheduler()) .build(); cache.put(1, 2); System.out.println(cache.getIfPresent(1)); Thread.sleep(6000); System.out.println(cache.getIfPresent(1)); 1234567891011121314151617181920212223242526272829Cache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfter(new Expiry&lt;Integer, Integer&gt;() &#123; // 创建1秒后过期，可以看到这里必须要用纳秒 @Override public long expireAfterCreate(@NonNull Integer key, @NonNull Integer value, long currentTime) &#123; return TimeUnit.SECONDS.toNanos(1); &#125; // 更新2秒后过期，可以看到这里必须要用纳秒 @Override public long expireAfterUpdate(@NonNull Integer key, @NonNull Integer value, long currentTime, @NonNegative long currentDuration) &#123; return TimeUnit.SECONDS.toNanos(2); &#125; // 读3秒后过期，可以看到这里必须要用纳秒 @Override public long expireAfterRead(@NonNull Integer key, @NonNull Integer value, long currentTime, @NonNegative long currentDuration) &#123; return TimeUnit.SECONDS.toNanos(3); &#125; &#125;).scheduler(Scheduler.systemScheduler()) .build(); cache.put(1, 2); System.out.println(cache.getIfPresent(1)); Thread.sleep(6000); System.out.println(cache.getIfPresent(1)); 写后重新计时 1234567891011121314151617181920// 设置写入后3秒后数据过期，2秒后如果有数据访问则刷新数据 LoadingCache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .refreshAfterWrite(2, TimeUnit.SECONDS) //刷新机制 .expireAfterWrite(3, TimeUnit.SECONDS) .build(new CacheLoader&lt;Integer, Integer&gt;() &#123; @Nullable @Override public Integer load(@NonNull Integer key) &#123; return getInDB(); &#125; &#125;); cache.put(1, getInDB()); // 休眠2.5秒，后取值 Thread.sleep(2500); System.out.println(cache.getIfPresent(1)); // 休眠1.5秒，后取值 Thread.sleep(1500); System.out.println(cache.getIfPresent(1)); 问题1说直接给Caffeine设置了最大缓存个数，会存在一个隐患，那便是当同时在线的玩家数超过最大缓存个数的情况下，会导致缓存被清，之后导致频繁读取数据库加载数据，让我在Caffeine的基础上，结合二级缓存解决这个问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 充当二级缓存用，生命周期仅活到下个gc */ private static Map&lt;Integer, WeakReference&lt;Integer&gt;&gt; secondCacheMap = new ConcurrentHashMap&lt;&gt;(); public static void test() throws InterruptedException &#123; // 设置最大缓存个数为1 LoadingCache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .maximumSize(1) // 设置put和remove的回调 .writer(new CacheWriter&lt;Integer, Integer&gt;() &#123; @Override public void write(@NonNull Integer key, @NonNull Integer value) &#123; secondCacheMap.put(key, new WeakReference&lt;&gt;(value)); System.out.println(&quot;触发CacheWriter.write，将key = &quot; + key + &quot;放入二级缓存中&quot;); &#125; @Override public void delete(@NonNull Integer key, @Nullable Integer value, @NonNull RemovalCause cause) &#123; switch (cause) &#123; case EXPLICIT: secondCacheMap.remove(key); System.out.println(&quot;触发CacheWriter&quot; + &quot;.delete，清除原因：主动清除，将key = &quot; + key + &quot;从二级缓存清除&quot;); break; case SIZE: System.out.println(&quot;触发CacheWriter&quot; + &quot;.delete，清除原因：缓存个数超过上限，key = &quot; + key); break; default: break; &#125; &#125; &#125;) .build(new CacheLoader&lt;Integer, Integer&gt;() &#123; @Nullable @Override public Integer load(@NonNull Integer key) &#123; WeakReference&lt;Integer&gt; value = secondCacheMap.get(key); if (value == null) &#123; return null; &#125; System.out.println(&quot;触发CacheLoader.load，从二级缓存读取key = &quot; + key); return value.get(); &#125; &#125;); cache.put(1, 1); cache.put(2, 2); // 由于清除缓存是异步的，因而睡眠1秒等待清除完成 Thread.sleep(1000); // 缓存超上限触发清除后 System.out.println(&quot;从Caffeine中get数据，key为1，value为&quot;+cache.get(1)); 淘汰监听123456789101112131415161718192021222324252627/** * @author xifanxiaxue * @date 2020/11/19 22:34 * @desc 淘汰通知 */public class CaffeineRemovalListenerTest &#123; @Test public void test() throws InterruptedException &#123; LoadingCache&lt;Integer, Integer&gt; cache = Caffeine.newBuilder() .expireAfterAccess(1, TimeUnit.SECONDS) .scheduler(Scheduler.systemScheduler()) // 增加了淘汰监听 .removalListener(((key, value, cause) -&gt; &#123; System.out.println(&quot;淘汰通知，key：&quot; + key + &quot;，原因：&quot; + cause); &#125;)) .build(new CacheLoader&lt;Integer, Integer&gt;() &#123; @Override public @Nullable Integer load(@NonNull Integer key) throws Exception &#123; return key; &#125; &#125;); cache.put(1, 2); Thread.currentThread().sleep(2000); &#125; 缓存一致性利用mq，来更新缓存，需要根据数据库数据判断缓存是否需要更新 利用cancel监控binlog日志更新缓存","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://duanyushuai.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"springMVC 源码分析","slug":"springmvc源码分析","date":"2023-01-06T02:02:49.137Z","updated":"2023-01-06T02:13:58.273Z","comments":true,"path":"2023/01/06/springmvc源码分析/","link":"","permalink":"http://duanyushuai.github.io/2023/01/06/springmvc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"springMVC 源码分析","categories":[],"tags":[]},{"title":"自控力","slug":"自控力","date":"2023-01-05T02:00:00.000Z","updated":"2023-03-24T08:49:41.326Z","comments":true,"path":"2023/01/05/自控力/","link":"","permalink":"http://duanyushuai.github.io/2023/01/05/%E8%87%AA%E6%8E%A7%E5%8A%9B/","excerpt":"","text":"自控力1. 冥想遇到难题有两个想法，专注自己的呼吸5分钟，帮助自己获得更好的选择 2. 关注自己的意志力强弱3. 意志力榜样4. 等待十分钟的诱惑","categories":[{"name":"读书","slug":"读书","permalink":"http://duanyushuai.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://duanyushuai.github.io/tags/%E8%AF%BB%E4%B9%A6/"}]},{"title":"redis限流","slug":"redis限流","date":"2022-11-22T02:00:00.000Z","updated":"2022-11-22T14:33:38.995Z","comments":true,"path":"2022/11/22/redis限流/","link":"","permalink":"http://duanyushuai.github.io/2022/11/22/redis%E9%99%90%E6%B5%81/","excerpt":"","text":"redis 限流","categories":[{"name":"redis","slug":"redis","permalink":"http://duanyushuai.github.io/categories/redis/"}],"tags":[{"name":"限流","slug":"限流","permalink":"http://duanyushuai.github.io/tags/%E9%99%90%E6%B5%81/"}]},{"title":"excel导入","slug":"excel导入","date":"2022-11-18T03:00:23.000Z","updated":"2022-10-18T14:07:28.242Z","comments":true,"path":"2022/11/18/excel导入/","link":"","permalink":"http://duanyushuai.github.io/2022/11/18/excel%E5%AF%BC%E5%85%A5/","excerpt":"","text":"excel导入百万数据导入1、 我遇到的数据量超级大，使用传统的POI方式来完成导入导出很明显会内存溢出，并且效率会非常低； 2、 数据量大直接使用select * from tableName肯定不行，一下子查出来300w条数据肯定会很慢； 3、 300w 数据导出到Excel时肯定不能都写在一个Sheet中，这样效率会非常低；估计打开都得几分钟； 4、 300w数据导出到Excel中肯定不能一行一行的导出到Excel中。频繁IO操作绝对不行； 5、 导入时300万数据存储到DB如果循环一条条插入也肯定不行； 6、导入时300w数据如果使用Mybatis的批量插入肯定不行，因为Mybatis的批量插入其实就是SQL的循环；一样很慢。 针对1：其实问题所在就是内存溢出，我们只要使用对上面介绍的POI方式即可，主要问题就是原生的POI解决起来相当麻烦。 经过查阅资料翻看到阿里的一款POI封装工具EasyExcel，上面问题等到解决； 针对2：不能一次性查询出全部数据，我们可以分批进行查询，只不过时多查询几次的问题，况且市面上分页插件很多。此问题好解决。 针对3：可以将300w条数据写到不同的Sheet中，每一个Sheet写一百万即可。 针对4：不能一行一行的写入到Excel上，我们可以将分批查询的数据分批写入到Excel中。 针对5：导入到DB时我们可以将Excel中读取的数据存储到集合中，到了一定数量，直接批量插入到DB中。 针对6：不能使用Mybatis的批量插入，我们可以使用JDBC的批量插入，配合事务来完成批量插入到DB。即 Excel读取分批+JDBC分批插入+事务。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public void dataExport300w(HttpServletResponse response) &#123; &#123; OutputStream outputStream = null; try &#123; long startTime = System.currentTimeMillis(); System.out.println(&quot;导出开始时间:&quot; + startTime); outputStream = response.getOutputStream(); ExcelWriter writer = new ExcelWriter(outputStream, ExcelTypeEnum.XLSX); String fileName = new String((&quot;excel100w&quot;).getBytes(), &quot;UTF-8&quot;); //title Table table = new Table(1); List&lt;List&lt;String&gt;&gt; titles = new ArrayList&lt;List&lt;String&gt;&gt;(); titles.add(Arrays.asList(&quot;onlineseqid&quot;)); titles.add(Arrays.asList(&quot;businessid&quot;)); titles.add(Arrays.asList(&quot;becifno&quot;)); titles.add(Arrays.asList(&quot;ivisresult&quot;)); titles.add(Arrays.asList(&quot;createdby&quot;)); titles.add(Arrays.asList(&quot;createddate&quot;)); titles.add(Arrays.asList(&quot;updateby&quot;)); titles.add(Arrays.asList(&quot;updateddate&quot;)); titles.add(Arrays.asList(&quot;risklevel&quot;)); table.setHead(titles); //模拟统计查询的数据数量这里模拟100w int count = 3000001; //记录总数:实际中需要根据查询条件进行统计即可 Integer totalCount = actResultLogMapper.findActResultLogByCondations(count); //每一个Sheet存放100w条数据 Integer sheetDataRows = ExcelConstants.PER_SHEET_ROW_COUNT; //每次写入的数据量20w Integer writeDataRows = ExcelConstants.PER_WRITE_ROW_COUNT; //计算需要的Sheet数量 Integer sheetNum = totalCount % sheetDataRows == 0 ? (totalCount / sheetDataRows) : (totalCount / sheetDataRows + 1); //计算一般情况下每一个Sheet需要写入的次数(一般情况不包含最后一个sheet,因为最后一个sheet不确定会写入多少条数据) Integer oneSheetWriteCount = sheetDataRows / writeDataRows; //计算最后一个sheet需要写入的次数 Integer lastSheetWriteCount = totalCount % sheetDataRows == 0 ? oneSheetWriteCount : (totalCount % sheetDataRows % writeDataRows == 0 ? (totalCount / sheetDataRows / writeDataRows) : (totalCount / sheetDataRows / writeDataRows + 1)); //开始分批查询分次写入 //注意这次的循环就需要进行嵌套循环了,外层循环是Sheet数目,内层循环是写入次数 List&lt;List&lt;String&gt;&gt; dataList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; sheetNum; i++) &#123; //创建Sheet Sheet sheet = new Sheet(i, 0); sheet.setSheetName(&quot;测试Sheet1&quot; + i); //循环写入次数: j的自增条件是当不是最后一个Sheet的时候写入次数为正常的每个Sheet写入的次数,如果是最后一个就需要使用计算的次数lastSheetWriteCount for (int j = 0; j &lt; (i != sheetNum - 1 ? oneSheetWriteCount : lastSheetWriteCount); j++) &#123; //集合复用,便于GC清理 dataList.clear(); //分页查询一次20w PageHelper.startPage(j + 1 + oneSheetWriteCount * i, writeDataRows); List&lt;ActResultLog&gt; reslultList = actResultLogMapper.findByPage100w(); if (!CollectionUtils.isEmpty(reslultList)) &#123; reslultList.forEach(item -&gt; &#123; dataList.add(Arrays.asList(item.getOnlineseqid(), item.getBusinessid(), item.getBecifno(), item.getIvisresult(), item.getCreatedby(), Calendar.getInstance().getTime().toString(), item.getUpdateby(), Calendar.getInstance().getTime().toString(), item.getRisklevel())); &#125;); &#125; //写数据 writer.write0(dataList, sheet, table); &#125; &#125; // 下载EXCEL response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + new String((fileName).getBytes(&quot;gb2312&quot;), &quot;ISO-8859-1&quot;) + &quot;.xlsx&quot;); response.setContentType(&quot;multipart/form-data&quot;); response.setCharacterEncoding(&quot;utf-8&quot;); writer.finish(); outputStream.flush(); //导出时间结束 long endTime = System.currentTimeMillis(); System.out.println(&quot;导出结束时间:&quot; + endTime + &quot;ms&quot;); System.out.println(&quot;导出所用时间:&quot; + (endTime - startTime) / 1000 + &quot;秒&quot;); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (outputStream != null) &#123; try &#123; outputStream.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 300W数据的导入解决思路1、首先是分批读取读取Excel中的300w数据，这一点EasyExcel有自己的解决方案，我们可以参考Demo即可，只需要把它分批的参数3000调大即可。我是用的20w；（一会儿代码一看就能明白） 2、其次就是往DB里插入，怎么去插入这20w条数据，当然不能一条一条的循环，应该批量插入这20w条数据，同样也不能使用Mybatis的批量插入语，因为效率也低。可以参考下面链接【Myabtis批量插入和JDBC批量插入性能对比】 3、使用JDBC+事务的批量操作将数据插入到数据库。（分批读取+JDBC分批插入+手动事务控制） 123456789101112// EasyExcel的读取Excel数据的API@Testpublic void import2DBFromExcel10wTest() &#123; String fileName = &quot;D:\\\\StudyWorkspace\\\\JavaWorkspace\\\\java_project_workspace\\\\idea_projects\\\\SpringBootProjects\\\\easyexcel\\\\exportFile\\\\excel300w.xlsx&quot;; //记录开始读取Excel时间,也是导入程序开始时间 long startReadTime = System.currentTimeMillis(); System.out.println(&quot;------开始读取Excel的Sheet时间(包括导入数据过程):&quot; + startReadTime + &quot;ms------&quot;); //读取所有Sheet的数据.每次读完一个Sheet就会调用这个方法 EasyExcel.read(fileName, new EasyExceGeneralDatalListener(actResultLogService2)).doReadAll(); long endReadTime = System.currentTimeMillis(); System.out.println(&quot;------结束读取Excel的Sheet时间(包括导入数据过程):&quot; + endReadTime + &quot;ms------&quot;);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 事件监听public class EasyExceGeneralDatalListener extends AnalysisEventListener&lt;Map&lt;Integer, String&gt;&gt; &#123; /** * 处理业务逻辑的Service,也可以是Mapper */ private ActResultLogService2 actResultLogService2; /** * 用于存储读取的数据 */ private List&lt;Map&lt;Integer, String&gt;&gt; dataList = new ArrayList&lt;Map&lt;Integer, String&gt;&gt;(); public EasyExceGeneralDatalListener() &#123; &#125; public EasyExceGeneralDatalListener(ActResultLogService2 actResultLogService2) &#123; this.actResultLogService2 = actResultLogService2; &#125; @Override public void invoke(Map&lt;Integer, String&gt; data, AnalysisContext context) &#123; //数据add进入集合 dataList.add(data); //size是否为100000条:这里其实就是分批.当数据等于10w的时候执行一次插入 if (dataList.size() &gt;= ExcelConstants.GENERAL_ONCE_SAVE_TO_DB_ROWS) &#123; //存入数据库:数据小于1w条使用Mybatis的批量插入即可; saveData(); //清理集合便于GC回收 dataList.clear(); &#125; &#125; /** * 保存数据到DB * * @param * @MethodName: saveData * @return: void */ private void saveData() &#123; actResultLogService2.import2DBFromExcel10w(dataList); dataList.clear(); &#125; /** * Excel中所有数据解析完毕会调用此方法 * * @param: context * @MethodName: doAfterAllAnalysed * @return: void */ @Override public void doAfterAllAnalysed(AnalysisContext context) &#123; saveData(); dataList.clear(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980//JDBC工具类public class JDBCDruidUtils &#123; private static DataSource dataSource; /* 创建数据Properties集合对象加载加载配置文件 */ static &#123; Properties pro = new Properties(); //加载数据库连接池对象 try &#123; //获取数据库连接池对象 pro.load(JDBCDruidUtils.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;)); dataSource = DruidDataSourceFactory.createDataSource(pro); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /* 获取连接 */ public static Connection getConnection() throws SQLException &#123; return dataSource.getConnection(); &#125; /** * 关闭conn,和 statement独对象资源 * * @param connection * @param statement * @MethodName: close * @return: void */ public static void close(Connection connection, Statement statement) &#123; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (statement != null) &#123; try &#123; statement.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 关闭 conn , statement 和resultset三个对象资源 * * @param connection * @param statement * @param resultSet * @MethodName: close * @return: void */ public static void close(Connection connection, Statement statement, ResultSet resultSet) &#123; close(connection, statement); if (resultSet != null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /* 获取连接池对象 */ public static DataSource getDataSource() &#123; return dataSource; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// Service中具体业务逻辑/** * 测试用Excel导入超过10w条数据,经过测试发现,使用Mybatis的批量插入速度非常慢,所以这里可以使用 数据分批+JDBC分批插入+事务来继续插入速度会非常快 * * @param * @MethodName: import2DBFromExcel10w * @return: java.util.Map&lt;java.lang.String, java.lang.Object&gt; */@Overridepublic Map&lt;String, Object&gt; import2DBFromExcel10w(List&lt;Map&lt;Integer, String&gt;&gt; dataList) &#123; HashMap&lt;String, Object&gt; result = new HashMap&lt;&gt;(); //结果集中数据为0时,结束方法.进行下一次调用 if (dataList.size() == 0) &#123; result.put(&quot;empty&quot;, &quot;0000&quot;); return result; &#125; //JDBC分批插入+事务操作完成对10w数据的插入 Connection conn = null; PreparedStatement ps = null; try &#123; long startTime = System.currentTimeMillis(); System.out.println(dataList.size() + &quot;条,开始导入到数据库时间:&quot; + startTime + &quot;ms&quot;); conn = JDBCDruidUtils.getConnection(); //控制事务:默认不提交 conn.setAutoCommit(false); String sql = &quot;insert into ACT_RESULT_LOG (onlineseqid,businessid,becifno,ivisresult,createdby,createddate,updateby,updateddate,risklevel) values&quot;; sql += &quot;(?,?,?,?,?,?,?,?,?)&quot;; ps = conn.prepareStatement(sql); //循环结果集:这里循环不支持&quot;烂布袋&quot;表达式 for (int i = 0; i &lt; dataList.size(); i++) &#123; Map&lt;Integer, String&gt; item = dataList.get(i); ps.setString(1, item.get(0)); ps.setString(2, item.get(1)); ps.setString(3, item.get(2)); ps.setString(4, item.get(3)); ps.setString(5, item.get(4)); ps.setTimestamp(6, new Timestamp(System.currentTimeMillis())); ps.setString(7, item.get(6)); ps.setTimestamp(8, new Timestamp(System.currentTimeMillis())); ps.setString(9, item.get(8)); //将一组参数添加到此 PreparedStatement 对象的批处理命令中。 ps.addBatch(); &#125; //执行批处理 ps.executeBatch(); //手动提交事务 conn.commit(); long endTime = System.currentTimeMillis(); System.out.println(dataList.size() + &quot;条,结束导入到数据库时间:&quot; + endTime + &quot;ms&quot;); System.out.println(dataList.size() + &quot;条,导入用时:&quot; + (endTime - startTime) + &quot;ms&quot;); result.put(&quot;success&quot;, &quot;1111&quot;); &#125; catch (Exception e) &#123; result.put(&quot;exception&quot;, &quot;0000&quot;); e.printStackTrace(); &#125; finally &#123; //关连接 JDBCDruidUtils.close(conn, ps); &#125; return result;&#125;","categories":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/tags/springboot/"}]},{"title":"设计模式","slug":"设计模式","date":"2022-11-08T09:21:31.529Z","updated":"2022-11-11T15:13:58.258Z","comments":true,"path":"2022/11/08/设计模式/","link":"","permalink":"http://duanyushuai.github.io/2022/11/08/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"[toc] 设计模式1.创建型模式1. 单例模式1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 2.原型创建重复对象 实现接口Cloneable 3.工厂**简单工厂 ** 12345678910/** * 工厂的产品 */public abstract class AbstractCar &#123; String engine; public abstract void run();&#125; 123456789101112public class MiniCar extends AbstractCar&#123; public MiniCar()&#123; this.engine = &quot;四缸水平对置发动机&quot;; &#125; @Override public void run() &#123; System.out.println(engine+&quot;--&gt; 嘟嘟嘟...&quot;); &#125;&#125; 1234567891011121314/** * 具体产品 */public class VanCar extends AbstractCar&#123; public VanCar()&#123; this.engine = &quot;单杠柴油机&quot;; &#125; @Override public void run() &#123; System.out.println(engine+&quot;--》嗒嗒嗒....&quot;); &#125;&#125; 123456789101112131415161718192021222324252627 * 简单工厂 * 1、产品数量极少 */public class WuLinSimpleFactory &#123; /** * * @param type Class: 好像具有扩展性，但是没有解决实际问题 * @return */ public AbstractCar newCar(String type)&#123; //核心方法：一切从简 if(&quot;van&quot;.equals(type))&#123; // 钣金、喷漆、放发动机、申请环保 return new VanCar(); &#125;else if(&quot;mini&quot;.equals(type))&#123; return new MiniCar(); &#125; //..... //更多的产品，违反开闭原则。应该直接扩展出一个类来造 return null; &#125;&#125; 4.建造者12//builder lombok 2.结构模式1.适配器模式已有两个接口，在不改变两个接口的情况下，完成两个接口的合并 1234567891011121314151617181920212223/** * 继承的方式：类结构模型，适配转换到了翻译器的功能上 * * */public class JPMoviePlayerAdapter extends Zh_JPTranslator implements Player &#123; private Player target;//被适配对象 public JPMoviePlayerAdapter(Player target)&#123; this.target = target; &#125; @Override public String play() &#123; String play = target.play(); //转换字幕 String translate = translate(play); System.out.println(&quot;日文：&quot;+translate); return play; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435package com.atguigu.design.structural.adapter.obj;import com.atguigu.design.structural.adapter.Player;import com.atguigu.design.structural.adapter.Translator;import com.atguigu.design.structural.adapter.Zh_JPTranslator;/** * 组合的方式：对象结构模型，适配转换到了翻译器的功能上 * * （继承、组合）、封装、多态 * * * */public class JPMoviePlayerAdapter implements Player &#123; //组合的方式 private Translator translator = new Zh_JPTranslator(); private Player target;//被适配对象 public JPMoviePlayerAdapter(Player target)&#123; this.target = target; &#125; @Override public String play() &#123; String play = target.play(); //转换字幕 String translate = translator.translate(play); System.out.println(&quot;日文：&quot;+translate); return play; &#125;&#125; 2. 桥接模式真正引起一个类变换的维度直接抽取出来，通过组合的方式侨接起来 12345678910111213141516171819202122/** * 1、抽象手机类 * 手机有各种销售渠道价格都不一样 * */public abstract class AbstractPhone &#123; //桥接在此.....设计期间就得想好 //桥接+适配器 ... AbstractSale sale; //分离渠道【桥接的关注点】// abstract int getPrice(); 如果这么写需要多少个实现。违反开闭原则 /** * 当前手机的描述 * @return */ abstract String getPhone(); public void setSale(AbstractSale sale) &#123; this.sale = sale; &#125; 123456789101112131415161718192021222324252627/** * 抽象销售渠道 * PhoneOnSale ==howToSale * PhoneOffSale == howToSale * PhoneStudentSale = howToSale * PhonePDD == howToSale * * */public abstract class AbstractSale &#123; private String type; private Integer price; public AbstractSale(String type,Integer price)&#123; this.type = type; this.price = price; &#125; String getSaleInfo()&#123; return &quot;渠道：&quot;+type+&quot;==&gt;&quot;+&quot;价格：&quot;+price; &#125; void howToSale()&#123; //都不一样 &#125;&#125; 3. 装饰器模式增强一个类 12//wrapper Pattern//已有的类功能不够用时，增强方法，当引用第三方就是适配器了 4.代理动态代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class JdkTiktokProxy&lt;T&gt; implements InvocationHandler &#123; private T target; //接受被代理对象 JdkTiktokProxy(T target)&#123; this.target = target; &#125; /** * 获取被代理对象的 代理对象 * @param t * @param &lt;T&gt; * @return */ public static&lt;T&gt; T getProxy(T t) &#123; /** * ClassLoader loader, 当前被代理对象的类加载器 * Class&lt;?&gt;[] interfaces, 当前被代理对象所实现的所有接口 * InvocationHandler h, * 当前被代理对象执行目标方法的时候我们使用h可以定义拦截增强方法 */ Object o = Proxy.newProxyInstance( t.getClass().getClassLoader(), t.getClass().getInterfaces(), //必须接口 new JdkTiktokProxy(t)); return (T)o; &#125; /** * 定义目标方法的拦截逻辑；每个方法都会进来的 * * @param proxy * @param method * @param args * @return * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //反射执行 System.out.println(&quot;真正执行被代理对象的方法&quot;); Object invoke = method.invoke(target, args); System.out.println(&quot;返回值：一堆美女&quot;); return invoke; &#125;&#125; 1234567891011121314151617181920212223242526/** * 动态代理模式： * JDK要求被代理对象必须有接口 * * 代理对象和目标对象的相同点在于都是同一个接口 */public class MainTest &#123; public static void main(String[] args) &#123; ManTikTok leiTikTok = new LeiTikTok(); /** * 动态代理机制。 */ ManTikTok proxy = JdkTiktokProxy.getProxy(leiTikTok); proxy.tiktok(); ((SellTikTok)proxy).sell(); //能不能代理被代理对象本类自己的方法?proxy只能转成接口类// ((LeiTikTok)proxy).haha(); System.out.println(Arrays.asList(proxy.getClass().getInterfaces())); &#125;&#125; cglib 12345678910111213141516171819202122232425262728293031323334353637/** * 1、使用cglib帮我们创建出代理对象 */public class CglibProxy &#123; //为任意对象创建代理 public static&lt;T&gt; T createProxy(T t)&#123; //1、创建一个增强器 Enhancer enhancer = new Enhancer(); //2、设置要增强哪个个类的功能。增强器为这个类动态创建一个子类 enhancer.setSuperclass(t.getClass()); //3、设置回调 enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, //为了能获取到原方法的一些元数据信息 Object[] args, MethodProxy proxy) throws Throwable &#123; //编写拦截的逻辑 System.out.println(&quot;cglib上场le .......xxx&quot;); //当前方法的信息// method.get// method.getAnnotation() //目标方法进行执行 Object invoke = proxy.invokeSuper(obj,args); return invoke; &#125; &#125;); Object o = enhancer.create(); return (T) o; &#125;&#125; 5.外观模式123456//去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。以此类比......//JAVA 的三层开发模式。//分布式系统的网关//Tomcat源码中的RequestFacade干什么的？//...... 6.组合模式1//树形结构 层级结构 7.享元模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//就是线程池/** * 足道店：这相当于享元工厂 * 店里面很多服务员。 * * 享元和原型 * 1、享元返回的是这个本人。 * 2、原型返回的是克隆人。 * */public class ZuDao &#123; private static Map&lt;String,AbstractWaitressFlyweight&gt; pool = new HashMap&lt;&gt;(); //享元，池子中有对象 static &#123; BeautifulWaitress waitress = new BeautifulWaitress(&quot;1111&quot;,&quot;张三&quot;,18); BeautifulWaitress waitress2 = new BeautifulWaitress(&quot;9527&quot;,&quot;李四&quot;,20); pool.put(waitress.id,waitress); pool.put(waitress2.id,waitress2); &#125; public void addWaitress(AbstractWaitressFlyweight waitressFlyweight)&#123; pool.put(UUID.randomUUID().toString(),waitressFlyweight); &#125; public static AbstractWaitressFlyweight getWaitress(String name)&#123; AbstractWaitressFlyweight flyweight = pool.get(name); if(flyweight == null)&#123; for (AbstractWaitressFlyweight value : pool.values()) &#123; //当前共享对象能否是否 if(value.isCanService())&#123; return value; &#125; &#125;; return null; &#125; return flyweight; &#125;&#125; 123456789101112131415161718192021222324252627/** * 具体享元类 */@AllArgsConstructorpublic class BeautifulWaitress extends AbstractWaitressFlyweight&#123; String id;//工号 String name;//名字 int age;//年龄 //以上是不变的 @Override void service() &#123; System.out.println(&quot;工号：&quot;+id+&quot;；&quot;+name+&quot; &quot;+age+&quot; 正在为您服务...&quot;); //改变外部状态 this.canService = false; &#125; @Override void end() &#123; System.out.println(&quot;工号：&quot;+id+&quot;；&quot;+name+&quot; &quot;+age+&quot; 服务结束...请给五星好评&quot;); this.canService = true; &#125;&#125; 3.行为模式1.模版方法123456789101112131415161718192021222324252627282930313233343536373839404142/** * 1、定义模板 */public abstract class CookTemplate &#123; /** * 定义算法： 定义好了模板 * 父类可以实现某些步骤 * 留关键给子类 */ public void cook()&#123; //定义算法步骤 heating(); //v addfood(); addsalt(); stirfry(); //v end(); //v &#125; //加热方法 public void heating()&#123; System.out.println(&quot;开火...&quot;); &#125;; //添加食物 public abstract void addfood(); //加盐 public abstract void addsalt(); //翻炒 public void stirfry()&#123; System.out.println(&quot;翻炒中...&quot;); &#125;; //出锅 public void end()&#123; System.out.println(&quot;出锅....&quot;); &#125;;&#125; 2.策略模式定义整体方法，可以将一部分抽离出来，装配策略 1234567891011121314151617181920/** * 环境类 */public class TeamGNR &#123; //抽取游戏策略算法，并进行引用 private GameStrategy gameStrategy; public void setGameStrategy(GameStrategy gameStrategy) &#123; this.gameStrategy = gameStrategy; &#125; public void startGame()&#123; System.out.println(&quot;游戏开始.....&quot;); //游戏策略 // gameStrategy.warStrategy(); System.out.println(&quot;win......&quot;); &#125;&#125; 3.状态模式状态机 123456789101112131415161718/** * 竞赛状态 */public class MatchState implements TeamState&#123; @Override public void playGame() &#123; System.out.println(&quot;全力以赴打比赛....&quot;); &#125; //状态模式的核心 @Override public TeamState next() &#123; return new VocationState(); &#125;&#125; 4.中介者模式 5.观察者模式12345678910111213141516171819202122232425262728** * 抽象观察者 */public abstract class AbstractFans &#123; List&lt;AbstractTikToker&gt; tikTokers;//双向观察 abstract void acceptMsg(String msg); void follow(AbstractTikToker tikToker)&#123; //主播增粉了 tikToker.addFans(this);// for (AbstractTikToker toker : tikTokers) &#123;//// &#125; &#125;;&#125;public class HumanFans extends AbstractFans &#123; @Override void acceptMsg(String msg) &#123; System.out.println(&quot;主播说：&quot;+msg); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 抖音主播 * * 粉丝观察主播.... */public abstract class AbstractTikToker &#123; //添加粉丝 abstract void addFans(AbstractFans fans); //通知粉丝 abstract void notifyFans(String msg);&#125;/** * 主播 * 双向观察 */public class MMTikToker extends AbstractTikToker&#123; //1、观察者的核心1 List&lt;AbstractFans&gt; fansList = new ArrayList&lt;&gt;(); void startSell() &#123; System.out.println(&quot;雷丰阳... 开始卖货...源码设计课&quot;); notifyFans(&quot;我开始卖东西了，是源码设计课，只要666&quot;); &#125; void endSell() &#123; System.out.println(&quot;雷丰阳... 结束卖货...源码设计课&quot;); notifyFans(&quot;课已经卖完了，记得五星好评...&quot;); &#125; @Override void addFans(AbstractFans fans) &#123; fansList.add(fans); &#125; @Override void notifyFans(String msg) &#123; //1、所有粉丝拿来通知 for (AbstractFans fans : fansList) &#123; fans.acceptMsg(msg); &#125; &#125;&#125; 6.备忘录模式1234//什么场景用到？//游戏存档//数据库保存点事务（savepoint）//session活化钝化 7.解释器模式 12345678910111213141516171819202122/** * 终结符表达式 * * 多少种解析规则就需要定义多少种规则类 * */public class TerminalExpression extends IDCardExpression &#123; String[] data; String symbol; //定义解析用的符号如 ： - public TerminalExpression(String[] data,String symbol)&#123; this.data = data; this.symbol = symbol; &#125; @Override boolean interpret(String expression) &#123; return false; &#125;&#125; 123456789101112131415161718192021/** * 非终结表达式 */public class OrExpression extends IDCardExpression &#123; //组合两个终结表达式。最终的判断结果是终结表达式判断出来的，这个表达式只是一个桥梁 private IDCardExpression cityExp; private IDCardExpression typeExp; public OrExpression(IDCardExpression cityExp, IDCardExpression typeExp) &#123; this.cityExp = cityExp; this.typeExp = typeExp; &#125; @Override boolean interpret(String expression) &#123; return cityExp.interpret(expression) || typeExp.interpret(expression); &#125;&#125; 9.命令模式mvc就是命令模式 10. 迭代器模式11.访问者模式 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。 123456789101112public class CPU extends Hardware&#123; public CPU(String command) &#123; super(command); &#125; @Override public void accept(Vistor vistor) &#123; //软件包要能访问当前硬件 vistor.visitCPU(this); &#125;&#125; 1234567891011public class Disk extends Hardware&#123; public Disk(String command) &#123; super(command); &#125; @Override public void accept(Vistor vistor) &#123; vistor.visitDisk(this); &#125;&#125; 123456789101112131415public abstract class Hardware &#123; String command;//封装硬件的处理指令 public Hardware(String command)&#123; this.command = command; &#125; public void work()&#123; System.out.println(command); &#125; //定义接受软件升级包的方法。这个方法应该具体硬件去实现 public abstract void accept(Vistor vistor);&#125; 123456789101112131415/** * 升级包可以更改指令 */public class UpdatePackage implements Vistor&#123; @Override public void visitCPU(CPU cpu) &#123; cpu.command+=&quot;；正在联网查询...&quot;; &#125; @Override public void visitDisk(Disk disk) &#123; disk.command+=&quot;；正在保存记录&quot;; &#125;&#125; 1234567public interface Vistor &#123; void visitCPU(CPU cpu); void visitDisk(Disk disk);&#125; 12.责任链模式1234567891011121314public class FilterChain implements Filter&#123; List&lt;Filter&gt; filterList = new ArrayList&lt;&gt;(); int cur = 0; void add(Filter filter)&#123; filterList.add(filter); &#125; @Override public void doFilter(Request req, Response res, FilterChain chain) &#123; final Filter filter = filterList.get(cur); cur++; filter.doFilter(req,res,chain); &#125;&#125; 12345public interface Filter &#123; void doFilter(Request req,Response res,FilterChain chain);&#125;","categories":[],"tags":[]},{"title":"树形结构","slug":"树形接口","date":"2022-11-04T09:20:20.358Z","updated":"2022-11-06T02:45:36.918Z","comments":true,"path":"2022/11/04/树形接口/","link":"","permalink":"http://duanyushuai.github.io/2022/11/04/%E6%A0%91%E5%BD%A2%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"树形结构怎么做**实体类 ** 123456789101112131415161718192021222324252627282930import lombok.Data;import java.util.ArrayList;import java.util.List;/** * @author变成派大星 */@Datapublic class Node &#123; private Integer Id; private String name; private Integer pid; private List&lt;Node&gt; treeNode = new ArrayList&lt;&gt;(); public Node(int id, int pid) &#123; this.Id = id; this.pid = pid; &#125; public Node(int id, int pid, String name) &#123; this(id, pid); this.name = name; &#125;&#125; 方法一12345678910111213141516171819202122232425public List&lt;Node&gt; handleTreeVo() &#123; Node first = new Node(1, 0, &quot;first&quot;); Node second = new Node(2, 1, &quot;second&quot;); Node third = new Node(3, 2, &quot;third&quot;); Node second001 = new Node(4, 1, &quot;second001&quot;); Node third001 = new Node(5, 4, &quot;third001&quot;); // 组装树状数据List&lt;Node&gt; nodes = Arrays.asList(first,second,third,second001,third001); return buildTree(nodes);&#125;public List&lt;Node&gt; buildTree(List&lt;Node&gt; nodes) &#123; //将这些非顶级节点的数据按pid进行分组 这个是根据pid为key 第一步过滤非Pid=0的节点 第二步进行分组 Map&lt;Integer, List&lt;Node&gt;&gt; nodeMap = nodes.stream().filter(node-&gt;node.getPid()!=0) .collect(Collectors.groupingBy(node -&gt; node.getPid())); //循环设置对应的子节点（根据id = pid） 上一步以pid为Key 所以就直接循环获取 nodes.forEach(node -&gt; node.setTreeNode(nodeMap.get(node.getId()))); //过滤第一层不是Pid为零的数据 也就是没有根节点的数据 List&lt;Node&gt; treeNode = nodes.stream().filter(node -&gt; node.getPid() == 0).collect(Collectors.toList()); return treeNode;&#125; 方法二12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import cn.hutool.core.collection.CollUtil;import com.baomidou.mybatisplus.core.toolkit.CollectionUtils;import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.function.BiConsumer;import java.util.function.Function;import java.util.function.Predicate;import java.util.stream.Collectors;/** * @author 变成派大星 */public class TreeUtils &#123; /** * @param list 源数据 * @param setChildListFn 设置递归的方法 * @param idFn 获取id的方法 * @param pidFn 获取父id的方法 * @param getRootCondition 获取根节点的提哦啊见 * @return 将List 转换成 Tree */ public static &lt;M, T&gt; List&lt;M&gt; listToTree(List&lt;M&gt; list, Function&lt;M, T&gt; idFn, Function&lt;M, T&gt; pidFn, BiConsumer&lt;M, List&lt;M&gt;&gt; setChildListFn, Predicate&lt;M&gt; getRootCondition) &#123; if (CollUtil.isEmpty(list)) return null; Map&lt;T, List&lt;M&gt;&gt; listMap = list.stream().collect(Collectors.groupingBy(pidFn)); list.forEach(model -&gt; setChildListFn.accept(model, listMap.get(idFn.apply(model)))); return list.stream().filter(getRootCondition).collect(Collectors.toList()); &#125; public static &lt;M&gt; List&lt;M&gt; treeToList(List&lt;M&gt; source, Function&lt;M, List&lt;M&gt;&gt; getChildListFn, BiConsumer&lt;M, List&lt;M&gt;&gt; setChildListFn, Predicate&lt;M&gt; getRootCondition) &#123; List&lt;M&gt; target = new ArrayList&lt;&gt;(); if (CollectionUtils.isNotEmpty(source)) &#123; treeToList(source, target, getChildListFn); target.forEach(model -&gt; setChildListFn.accept(model, null)); target.addAll(target.stream().filter(getRootCondition).collect(Collectors.toList())); &#125; return target; &#125; private static &lt;F&gt; void treeToList(List&lt;F&gt; source, List&lt;F&gt; target, Function&lt;F, List&lt;F&gt;&gt; getChildListFn) &#123; if (CollectionUtils.isNotEmpty(source)) &#123; target.addAll(source); source.forEach(model -&gt; &#123; List&lt;F&gt; childList = getChildListFn.apply(model); if (CollectionUtils.isNotEmpty(childList)) &#123; treeToList(childList, target, getChildListFn); &#125; &#125;); &#125; &#125;&#125; 例子 123456789101112public List&lt;Node&gt; handleTree()&#123; Node first = new Node(1, 0, &quot;first&quot;); Node second = new Node(2, 1, &quot;second&quot;); Node third = new Node(3, 2, &quot;third&quot;); Node second001 = new Node(4, 1, &quot;second001&quot;); Node third001 = new Node(5, 4, &quot;third001&quot;); List&lt;Node&gt; nodes = Arrays.asList(first,second,third,second001,third001); List&lt;Node&gt; nodeList = TreeUtils.listToTree(nodes, Node::getId, Node::getPid, Node::setTreeNode, (l) -&gt; l.getPid() == 0); // 树状结构转换成 List 也就是还原数据 return TreeUtils.treeToList(nodeList, Node::getTreeNode, Node::setTreeNode, (l) -&gt; l.getPid() == 0);&#125;","categories":[],"tags":[]},{"title":"链表","slug":"算法","date":"2022-10-26T12:26:17.945Z","updated":"2022-11-03T10:53:46.135Z","comments":true,"path":"2022/10/26/算法/","link":"","permalink":"http://duanyushuai.github.io/2022/10/26/%E7%AE%97%E6%B3%95/","excerpt":"","text":"链表1. 反转列表12345678910111213141516171819202122232425262728293031323334353637/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; ListNode rHead = new ListNode(-1); while(head!=null)&#123; ListNode p = head; head = head.next; p.next = rHead.next; rHead.next = p; &#125; return rHead.next; &#125;&#125;public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; ListNode newHead = null; ListNode temp =null; while(head!=null)&#123; temp = head.next; head.next = newHead; newHead = head; head = temp; &#125; return newHead; &#125;&#125; 2. 列表执行区间内反转将一个节点数为 size 链表 m 位置到 n 位置之间的区间反转，要求时间复杂度 O(n)O(n)，空间复杂度 O(1)O(1)。例如：给出的链表为 1\\to 2 \\to 3 \\to 4 \\to 5 \\to NULL1→2→3→4→5→NUL**L, m&#x3D;2,n&#x3D;4m&#x3D;2,n&#x3D;4,返回 1\\to 4\\to 3\\to 2\\to 5\\to NULL1→4→3→2→5→NUL**L. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head ListNode类 * @param m int整型 * @param n int整型 * @return ListNode类 */ // 解法一：双指针(两次遍历) //说明：方便理解，以下注释中将用left，right分别代替m,n节点 public ListNode reverseBetween (ListNode head, int m, int n) &#123; //设置虚拟头节点 ListNode dummyNode = new ListNode(-1); dummyNode.next = head; ListNode pre = dummyNode; //1.走left-1步到left的前一个节点 for(int i=0;i&lt;m-1;i++)&#123; pre = pre.next; &#125; //2.走roght-left+1步到right节点 ListNode rigthNode = pre; for(int i=0;i&lt;n-m+1;i++)&#123; rigthNode = rigthNode.next; &#125; //3.截取出一个子链表 ListNode leftNode = pre.next; ListNode cur = rigthNode.next; //4.切断链接 pre.next=null; rigthNode.next=null; //5.反转局部链表 reverseLinkedList(leftNode); //6.接回原来的链表 pre.next = rigthNode; leftNode.next = cur; return dummyNode.next; &#125; //反转局部链表 private void reverseLinkedList(ListNode head)&#123; ListNode pre = null; ListNode cur = head; while(cur!=null)&#123; //Cur_next 指向cur节点的下一个节点 ListNode Cur_next = cur.next; cur.next = pre; pre = cur; cur = Cur_next ; &#125; &#125;&#125; 3. 链表每k组反转将给出的链表中的节点每 k 个一组翻转，返回翻转后的链表如果链表中的节点数不是 k 的倍数，将最后剩下的节点保持原样你不能更改节点中的值，只能更改节点本身。 1234567891011121314151617181920212223242526272829import java.util.*;public class Solution &#123; public ListNode reverseKGroup (ListNode head, int k) &#123; //找到每次翻转的尾部 ListNode tail = head; //遍历k次到尾部 for(int i = 0; i &lt; k; i++)&#123; //如果不足k到了链表尾，直接返回，不翻转 if(tail == null) return head; tail = tail.next; &#125; //翻转时需要的前序和当前节点 ListNode pre = null; ListNode cur = head; //在到达当前段尾节点前 while(cur != tail)&#123; //翻转 ListNode temp = cur.next; cur.next = pre; pre = cur; cur = temp; &#125; //当前尾指向下一段要翻转的链表 head.next = reverseKGroup(tail, k); return pre; &#125;&#125; 4. 合并两个排序的链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode Merge(ListNode list1, ListNode list2) &#123; ListNode temp = new ListNode(-1); ListNode head = temp; while (list1 != null &amp;&amp; list2 != null) &#123; if (list1.val &lt;= list2.val) &#123; temp.next = list1; temp = temp.next; list1 = list1.next; &#125; else &#123; temp.next = list2; temp = temp.next; list2 = list2.next; &#125; &#125; if (list1 == null) &#123; temp.next = list2; &#125; if (list2 == null) &#123; temp.next = list1; &#125; return head.next; &#125;&#125;//递归public class Solution &#123; public ListNode Merge(ListNode list1,ListNode list2) &#123; // list1 list2为空的情况 if(list1 == null || list2 == null)&#123; return list1 != null ? list1 : list2; &#125; // 两个链表元素依次对比 if(list1.val &lt;= list2.val)&#123; // 递归计算 list1.next, list2 list1.next = Merge(list1.next, list2); return list1; &#125;else&#123; // 递归计算 list1, list2.next list2.next = Merge(list1, list2.next); return list2; &#125; &#125;&#125; 5. 合并k个已排序的列表123456789101112131415161718192021222324252627282930import java.util.*;public class Solution &#123; public ListNode mergeKLists(ArrayList&lt;ListNode&gt; lists) &#123; //小顶堆 Queue&lt;ListNode&gt; pq = new PriorityQueue&lt;&gt;((v1, v2) -&gt; v1.val - v2.val); //遍历所有链表第一个元素 for (int i = 0; i &lt; lists.size(); i++) &#123; //不为空则加入小顶堆 if (lists.get(i) != null) pq.offer(lists.get(i)); &#125; //加一个表头 ListNode res = new ListNode(-1); ListNode head = res; //直到小顶堆为空 while (!pq.isEmpty()) &#123; //取出最小的元素 ListNode temp = pq.poll(); //连接 head.next = temp; head = head.next; //每次取出链表的后一个元素加入小顶堆 if (temp.next != null) pq.add(temp.next); &#125; //去掉表头 return res.next; &#125;&#125; 6. 链表中的环的入口节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode EntryNodeOfLoop(ListNode pHead) &#123; if (pHead == null) return null; ListNode slow = pHead; ListNode fast = pHead; while (fast != null &amp;&amp; fast.next != null) &#123; fast = fast.next.next; slow = slow.next; if (slow == fast) break; &#125; if (fast == null || fast.next == null) return null; fast = pHead; while (fast != slow) &#123; fast = fast.next; slow = slow.next; &#125; return fast; &#125;&#125;// 哈希表 public ListNode EntryNodeOfLoop(ListNode pHead) &#123; // 使用set来记录出现的结点 HashSet&lt;ListNode&gt; set = new HashSet&lt;&gt;(); while(pHead != null)&#123; // 当set中包含结点，说明第一次出现重复的结点，即环的入口结点 if(set.contains(pHead))&#123; return pHead; &#125; // set中加入未重复的结点 set.add(pHead); pHead = pHead.next; &#125; return null; &#125; 7. 删除链表最后K的节点12345678910111213141516171819202122232425262728293031323334353637import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * public ListNode(int val) &#123; * this.val = val; * &#125; * &#125; */public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param pHead ListNode类 * @param k int整型 * @return ListNode类 */ public ListNode FindKthToTail (ListNode pHead, int k) &#123; // write code here ListNode temp = pHead; for (int i = 0; i &lt; k; i++) &#123; if (temp == null) &#123; return temp; &#125; temp = temp.next; &#125; while (temp != null) &#123; pHead = pHead.next; temp = temp.next; &#125; return pHead; &#125;&#125; 8.删除链表倒数第n的节点12345678910111213141516171819202122232425262728293031323334import java.util.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head ListNode类 * @param n int整型 * @return ListNode类 */ public ListNode removeNthFromEnd (ListNode head, int n) &#123; // write code here ListNode temp = head; for (int i = 0; i &lt; n + 1; i++) &#123; if (temp == null) &#123; return head.next; &#125; temp = temp.next; &#125; ListNode pre = head; while (temp != null) &#123; pre = pre.next; temp = temp.next; &#125; pre.next = pre.next.next; return head; &#125;&#125; 9. 寻找两个链表公共节点1234567891011public class Solution &#123; public ListNode FindFirstCommonNode(ListNode pHead1, ListNode pHead2) &#123; ListNode l1 = pHead1; ListNode l2 = pHead2; while (l1 != l2) &#123; l1 = (l1 == null) ? pHead2 : l1.next; l2 = (l2 == null) ? pHead1 : l2.next; &#125; return l1; &#125;&#125; 10. 链表相加例如：链表 1 为 9-&gt;3-&gt;7，链表 2 为 6-&gt;3，最后生成新的结果链表为 1-&gt;0-&gt;0-&gt;0。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.util.*;import java.lang.*;/* * public class ListNode &#123; * int val; * ListNode next = null; * &#125; */public class Solution &#123; /** * * @param head1 ListNode类 * @param head2 ListNode类 * @return ListNode类 */ public ListNode addInList (ListNode head1, ListNode head2) &#123; // write code here if (head1 == null) &#123; return head2; &#125; if (head2 == null) &#123; return head1; &#125; head1 = reverse(head1); head2 = reverse(head2); ListNode head = new ListNode(-1); ListNode newHead = head; int temp = 0; while (head1 != null || head2 != null) &#123; int val = temp; if (head1 != null) &#123; val += head1.val; head1 = head1.next; &#125; if (head2 != null) &#123; val += head2.val; head2 = head2.next; &#125; temp = val / 10; newHead.next = new ListNode(val % 10); newHead = newHead.next; &#125; if (temp &gt; 0) &#123; newHead.next = new ListNode(temp); &#125; return reverse(head.next); &#125; public ListNode reverse(ListNode head) &#123; ListNode rHead = new ListNode(-1); ListNode temp = head; while (temp != null) &#123; temp = temp.next; head.next = rHead.next; rHead.next = head; head = temp; &#125; return rHead.next; &#125;&#125;","categories":[],"tags":[{"name":"链表","slug":"链表","permalink":"http://duanyushuai.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"spring Validation 学习","slug":"spring validation","date":"2022-10-14T12:00:00.000Z","updated":"2022-10-18T13:42:45.571Z","comments":true,"path":"2022/10/14/spring validation/","link":"","permalink":"http://duanyushuai.github.io/2022/10/14/spring%20validation/","excerpt":"","text":"spring Validation 学习统一异常处理1234567891011121314151617181920212223@RestControllerAdvicepublic class CommonExceptionHandler &#123; @ExceptionHandler(&#123;MethodArgumentNotValidException.class&#125;) @ResponseStatus(HttpStatus.OK) @ResponseBody public Result handleMethodArgumentNotValidException(MethodArgumentNotValidException ex) &#123; BindingResult bindingResult = ex.getBindingResult(); StringBuilder sb = new StringBuilder(&quot;校验失败:&quot;); for (FieldError fieldError : bindingResult.getFieldErrors()) &#123; sb.append(fieldError.getField()).append(&quot;：&quot;).append(fieldError.getDefaultMessage()).append(&quot;, &quot;); &#125; String msg = sb.toString(); return Result.fail(BusinessCode.参数校验失败, msg); &#125; @ExceptionHandler(&#123;ConstraintViolationException.class&#125;) @ResponseStatus(HttpStatus.OK) @ResponseBody public Result handleConstraintViolationException(ConstraintViolationException ex) &#123; return Result.fail(BusinessCode.参数校验失败, ex.getMessage()); &#125;&#125; 嵌套校验某个字段也是一个对象，加Valid注解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Datapublic class UserDTO &#123; @Min(value = 10000000000000000L, groups = Update.class) private Long userId; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Length(min = 2, max = 10, groups = &#123;Save.class, Update.class&#125;) private String userName; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Length(min = 6, max = 20, groups = &#123;Save.class, Update.class&#125;) private String account; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Length(min = 6, max = 20, groups = &#123;Save.class, Update.class&#125;) private String password; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Valid private Job job; @Data public static class Job &#123; @Min(value = 1, groups = Update.class) private Long jobId; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Length(min = 2, max = 10, groups = &#123;Save.class, Update.class&#125;) private String jobName; @NotNull(groups = &#123;Save.class, Update.class&#125;) @Length(min = 2, max = 10, groups = &#123;Save.class, Update.class&#125;) private String position; &#125; /** * 保存的时候校验分组 */ public interface Save &#123; &#125; /** * 更新的时候校验分组 */ public interface Update &#123; &#125;&#125; 集合校验123456789101112public class ValidationList&lt;E&gt; implements List&lt;E&gt; &#123; @Delegate // @Delegate是lombok注解 @Valid // 一定要加@Valid注解 public List&lt;E&gt; list = new ArrayList&lt;&gt;(); // 一定要记得重写toString方法 @Override public String toString() &#123; return list.toString(); &#125;&#125; controller 12345@PostMapping(&quot;/saveList&quot;)public Result saveList(@RequestBody @Validated(UserDTO.Save.class) ValidationList&lt;UserDTO&gt; userList) &#123; // 校验通过，才会执行业务逻辑处理 return Result.ok();&#125; 自定义约束注解123456789101112131415@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)@Retention(RUNTIME)@Documented@Constraint(validatedBy = &#123;EncryptIdValidator.class&#125;)public @interface EncryptId &#123; // 默认错误消息 String message() default &quot;加密id格式错误&quot;; // 分组 Class&lt;?&gt;[] groups() default &#123;&#125;; // 负载 Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 实现ConstraintValidator接口编写约束校验器 1234567891011121314public class EncryptIdValidator implements ConstraintValidator&lt;EncryptId, String&gt; &#123; private static final Pattern PATTERN = Pattern.compile(&quot;^[a-f\\d]&#123;32,256&#125;$&quot;); @Override public boolean isValid(String value, ConstraintValidatorContext context) &#123; // 不为null才进行校验 if (value != null) &#123; Matcher matcher = PATTERN.matcher(value); return matcher.find(); &#125; return true; &#125;&#125; 编程式校验1Set&lt;ConstraintViolation&lt;UserDTO&gt;&gt; validate = globalValidator.validate(userDTO, UserDTO.Save.class); Validator实现原理requestBody参数校验实现原理在spring-mvc中，RequestResponseBodyMethodProcessor是用于解析@RequestBody标注的参数以及处理@ResponseBody标注方法的返回值的。显然，执行参数校验的逻辑肯定就在解析参数的方法resolveArgument()中： 1234567891011121314151617181920212223242526public class RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessor &#123; @Override public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception &#123; parameter = parameter.nestedIfOptional(); //将请求数据封装到DTO对象中 Object arg = readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType()); String name = Conventions.getVariableNameForParameter(parameter); if (binderFactory != null) &#123; WebDataBinder binder = binderFactory.createBinder(webRequest, arg, name); if (arg != null) &#123; // 执行数据校验 validateIfApplicable(binder, parameter); if (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123; throw new MethodArgumentNotValidException(parameter, binder.getBindingResult()); &#125; &#125; if (mavContainer != null) &#123; mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult()); &#125; &#125; return adaptArgumentIfNecessary(arg, parameter); &#125;&#125; 可以看到，resolveArgument()调用了validateIfApplicable()进行参数校验。 1234567891011121314151617protected void validateIfApplicable(WebDataBinder binder, MethodParameter parameter) &#123; // 获取参数注解，比如@RequestBody、@Valid、@Validated Annotation[] annotations = parameter.getParameterAnnotations(); for (Annotation ann : annotations) &#123; // 先尝试获取@Validated注解 Validated validatedAnn = AnnotationUtils.getAnnotation(ann, Validated.class); //如果直接标注了@Validated，那么直接开启校验。 //如果没有，那么判断参数前是否有Valid起头的注解。 if (validatedAnn != null || ann.annotationType().getSimpleName().startsWith(&quot;Valid&quot;)) &#123; Object hints = (validatedAnn != null ? validatedAnn.value() : AnnotationUtils.getValue(ann)); Object[] validationHints = (hints instanceof Object[] ? (Object[]) hints : new Object[] &#123;hints&#125;); //执行校验 binder.validate(validationHints); break; &#125; &#125;&#125; 可以看到，resolveArgument()调用了validateIfApplicable()进行参数校验。 1234567891011121314151617protected void validateIfApplicable(WebDataBinder binder, MethodParameter parameter) &#123; // 获取参数注解，比如@RequestBody、@Valid、@Validated Annotation[] annotations = parameter.getParameterAnnotations(); for (Annotation ann : annotations) &#123; // 先尝试获取@Validated注解 Validated validatedAnn = AnnotationUtils.getAnnotation(ann, Validated.class); //如果直接标注了@Validated，那么直接开启校验。 //如果没有，那么判断参数前是否有Valid起头的注解。 if (validatedAnn != null || ann.annotationType().getSimpleName().startsWith(&quot;Valid&quot;)) &#123; Object hints = (validatedAnn != null ? validatedAnn.value() : AnnotationUtils.getValue(ann)); Object[] validationHints = (hints instanceof Object[] ? (Object[]) hints : new Object[] &#123;hints&#125;); //执行校验 binder.validate(validationHints); break; &#125; &#125;&#125; 看到这里，大家应该能明白为什么这种场景下@Validated、@Valid两个注解可以混用。我们接下来继续看WebDataBinder.validate()实现。 12345678@Overridepublic void validate(Object target, Errors errors, Object... validationHints) &#123; if (this.targetValidator != null) &#123; processConstraintViolations( //此处调用Hibernate Validator执行真正的校验 this.targetValidator.validate(target, asValidationGroups(validationHints)), errors); &#125;&#125; 最终发现底层最终还是调用了Hibernate Validator进行真正的校验处理。 方法级别的参数校验实现原理上面提到的将参数一个个平铺到方法参数中，然后在每个参数前面声明约束注解的校验方式，就是方法级别的参数校验。 实际上，这种方式可用于任何Spring Bean的方法上，比如Controller/Service等。其底层实现原理就是AOP，具体来说是通过MethodValidationPostProcessor动态注册AOP切面，然后使用MethodValidationInterceptor对切点方法织入增强。 1234567891011121314public class MethodValidationPostProcessor extends AbstractBeanFactoryAwareAdvisingPostProcessorimplements InitializingBean &#123; @Override public void afterPropertiesSet() &#123; //为所有`@Validated`标注的Bean创建切面 Pointcut pointcut = new AnnotationMatchingPointcut(this.validatedAnnotationType, true); //创建Advisor进行增强 this.advisor = new DefaultPointcutAdvisor(pointcut, createMethodValidationAdvice(this.validator)); &#125; //创建Advice，本质就是一个方法拦截器 protected Advice createMethodValidationAdvice(@Nullable Validator validator) &#123; return (validator != null ? new MethodValidationInterceptor(validator) : new MethodValidationInterceptor()); &#125;&#125; 接着看一下MethodValidationInterceptor： 1234567891011121314151617181920212223242526272829303132333435public class MethodValidationInterceptor implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; //无需增强的方法，直接跳过 if (isFactoryBeanMetadataMethod(invocation.getMethod())) &#123; return invocation.proceed(); &#125; //获取分组信息 Class&lt;?&gt;[] groups = determineValidationGroups(invocation); ExecutableValidator execVal = this.validator.forExecutables(); Method methodToValidate = invocation.getMethod(); Set&lt;ConstraintViolation&lt;Object&gt;&gt; result; try &#123; //方法入参校验，最终还是委托给Hibernate Validator来校验 result = execVal.validateParameters( invocation.getThis(), methodToValidate, invocation.getArguments(), groups); &#125; catch (IllegalArgumentException ex) &#123; ... &#125; //有异常直接抛出 if (!result.isEmpty()) &#123; throw new ConstraintViolationException(result); &#125; //真正的方法调用 Object returnValue = invocation.proceed(); //对返回值做校验，最终还是委托给Hibernate Validator来校验 result = execVal.validateReturnValue(invocation.getThis(), methodToValidate, returnValue, groups); //有异常直接抛出 if (!result.isEmpty()) &#123; throw new ConstraintViolationException(result); &#125; return returnValue; &#125;&#125; 实际上，不管是requestBody参数校验还是方法级别的校验，最终都是调用Hibernate Validator执行校验，Spring Validation只是做了一层封装。","categories":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/tags/springboot/"}]},{"title":"springboot动态定时任务","slug":"springboot定时任务","date":"2022-10-10T12:00:00.000Z","updated":"2022-10-18T13:42:48.636Z","comments":true,"path":"2022/10/10/springboot定时任务/","link":"","permalink":"http://duanyushuai.github.io/2022/10/10/springboot%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"","text":"springboot动态定时任务12345678910111213141516171819202122232425262728293031323334@Data@Slf4j@Component@PropertySource(&quot;classpath:/task-config.ini&quot;)public class ScheduleTask implements SchedulingConfigurer &#123; @Value(&quot;$&#123;printTime.cron&#125;&quot;) private String cron; private Long timer = 10000L; @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) &#123; // 动态使用cron表达式设置循环间隔 taskRegistrar.addTriggerTask(new Runnable() &#123; @Override public void run() &#123; log.info(&quot;Current time： &#123;&#125;&quot;, LocalDateTime.now()); &#125; &#125;, new Trigger() &#123; @Override public Date nextExecutionTime(TriggerContext triggerContext) &#123; // 使用CronTrigger触发器，可动态修改cron表达式来操作循环规则// CronTrigger cronTrigger = new CronTrigger(cron);// Date nextExecutionTime = cronTrigger.nextExecutionTime(triggerContext); // 使用不同的触发器，为设置循环时间的关键，区别于CronTrigger触发器，该触发器可随意设置循环间隔时间，单位为毫秒 PeriodicTrigger periodicTrigger = new PeriodicTrigger(timer); Date nextExecutionTime = periodicTrigger.nextExecutionTime(triggerContext); return nextExecutionTime; &#125; &#125;); &#125;&#125; 除了上面的借助cron表达式的方法，还有另一种触发器，区别于CronTrigger触发器，该触发器可随意设置循环间隔时间，不像cron表达式只能定义小于等于间隔59秒","categories":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/categories/springboot/"}],"tags":[{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/tags/springboot/"}]},{"title":"SpringSecurity","slug":"SpringSecuity","date":"2022-08-27T07:58:07.374Z","updated":"2023-04-03T09:28:06.982Z","comments":true,"path":"2022/08/27/SpringSecuity/","link":"","permalink":"http://duanyushuai.github.io/2022/08/27/SpringSecuity/","excerpt":"","text":"SpringSecurity1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; SpringSecurity是一个过滤器链 UsernamePasswordAuthenticationFilter: 负责填写用户名密码后的登陆请求 ExceptionTranslationFilter: 处理过滤器链中跑出的任何AccessDeniedException和AuthenticationException FilterSecurityInterceptor: 负责权限校验的过滤器 userDetailsService 创建继承UsernamePasswordAuthenticationFilter 重写三个方法 创建类实现UserDetailService 编写查询数据过程，返回user 对象，安全框架提供的对象 12345678public UserDetails loadUserByUsername(String s)&#123; //查询数据库 User user = userMapper.get(); List&lt;GrantedAuthority&gt; authss = AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;role&quot;); return new User(user.getUsername(),user.getPassword,auths)&#125; PasswordEncoder 加密类 基于权限和角色进行访问控制hasAuthoriy方法 1.antMatchers(&quot;/test/index&quot;).hasAuthority(&quot;admin&quot;) 12List&lt;GrantedAuthority&gt; authss = AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;admin&quot;); hasAnyAuthority1.antMatchers(&quot;/test/index&quot;).hasAnyAuthority(&quot;admin,manage&quot;) spring cloud 加入SpringSecurityPasswordEncoder 密码处理12345678public class DefaultPasswordEncoder implements PasswordEncoder &#123; @Override public String encode (CharSequence charSequence)&#123;&#125;; @Override public boolean matches(CharSequence charSequence, String s)&#123;&#125;;&#125; TokenManager token操作工具类123456public class TokenManager &#123; public String createToken (String username)&#123;&#125;; public String getUserInfoFromToken(String token)&#123;&#125;;&#125; LogoutHandler 退出1234567891011public class TokenLogoutHandler implements LogoutHandler &#123; @Override public void logout(HttpServletRequest request,HttpservletRespose response,Authentication authentication)&#123; String token = request.getHander(&quot;token&quot;); if(token != null)&#123; string username = TokenManager.getUserInfoFromToken(); redis.remove(username); &#125; &#125;&#125; UsernamePasswordAuthenticationFilter 登陆过滤器","categories":[],"tags":[]},{"title":"JWT理解","slug":"Jwt理解","date":"2022-08-18T02:00:00.000Z","updated":"2022-08-28T06:35:00.527Z","comments":true,"path":"2022/08/18/Jwt理解/","link":"","permalink":"http://duanyushuai.github.io/2022/08/18/Jwt%E7%90%86%E8%A7%A3/","excerpt":"","text":"JWT理解jwt组成 标头（Header） 有效载荷（Payload） 签名（ Signature） 格式 xxx.yyy.zzz 标头令牌类型和所属签名 base64 编码 1234&#123; &quot;alg&quot;: &quot;HS256&quot; &quot;typ&quot;: &quot;jwt&quot;&#125; 有效载荷声明的实体。base64编码 12345&#123; &quot;sub&quot;: &quot;2123&quot; &quot;name&quot;: &quot;dd&quot; &quot;admin&quot;: true&#125; 签名使用密钥对header和payload进行签名，防止被容被篡改 1HMACSHA256(BASE64UrlEncode(header)+.+BASE64UrlEncode(payload),secret); 示例12345678910111213141516171819@Test public void test1()&#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); Calendar instance = Calendar.getInstance(); instance.add(Calendar.SECOND,20 ); final String username = JWT.create().withHeader(map) .withClaim(&quot;username&quot;, &quot;123&quot;) .withExpiresAt(instance.getTime()) .sign(Algorithm.HMAC256(&quot;123&quot;)); System.out.println(username ); &#125; @Test public void Test2()&#123; final JWTVerifier jwtVerifier = JWT.require(Algorithm.HMAC256(&quot;123&quot;)).build(); DecodedJWT verify = jwtVerifier.verify(&quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE2NjE1ODI2NDcsInVzZXJuYW1lIjoiMTIzIn0.b45eaJCa5uzUdGIfXfrjhw73AdzH-MXgkAI8hOY6wYU&quot;); System.out.println(verify); &#125;","categories":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/categories/java-web/"}],"tags":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/tags/java-web/"}]},{"title":"分布式事务","slug":"事务","date":"2022-08-14T09:48:41.791Z","updated":"2022-10-09T11:15:33.189Z","comments":true,"path":"2022/08/14/事务/","link":"","permalink":"http://duanyushuai.github.io/2022/08/14/%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"事务数据库事务特性原子性 一致性 隔离性 持久性 事务的隔离级别 Read uncommitted 读未提交读 ，读到其他事务未提交的数据，脏读 Read committed 读提交读，读到另一个事务的提交数据，在一个事务中，读取的数据不一样，形成不可重复读 Repeatable read mysql 默认的隔离级别，在同一个事务里，select 的结果是事务开始时时间点的状态，因此，同样的 select 操作读到的结果会是一致的，但是，会有幻读现象。MySQL 的 InnoDB 引擎可以通过 next-key locks 机制来避免幻读。 Serializable 序列化 事务的传播行为1、PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务， 就加入该事务，该设置是最常用的设置。 2、PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当 前不存在事务，就以非事务执行。 3、PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果 当前不存在事务，就抛出异常。 4、PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 5、PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当 前事务挂起。 6、PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 7、PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务， 则执行与 PROPAGATION_REQUIRED 类似的操作。 同一个对象内事务方法互相调失效，原因绕过了代理对象 解决：使用代理对象来调用事务方法 1）、引入aop-starter;spring-boot-starter-aop; 引入aspectj 2）、@EnableAspectJAutoProxy; 开启 aspectj 动态代理功能，以后的代理对象都是aspectj 0）、导入 spring-boot-starter-aop 1）、@EnableTransactionManagement(proxyTargetClass &#x3D; true) 2）、@EnableAspectJAutoProxy(exposeProxy&#x3D;true) 3）、AopContext.currentProxy() 调用方法 分布式事务CAP 原理CAP 原则又称 CAP 定理，指的是在一个分布式系统中 一致性（Consistency）： 在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本） 可用性（Availability） 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据 更新具备高可用性） 分区容错性（Partition tolerance） 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（ partition）。 分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。 CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。 一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们， 剩下的 C 和 A 无法同时做到。 分布式系统中实现一致性的 raft 算法、paxos http://thesecretlivesofdata.com/raft/ 分布式事务解决方案2PC模式数据库支持的 2PC【2 phase commit 二阶提交】，又叫做 XA Transactions。 MySQL 从 5.5 版本开始支持，SQL Server 2005 开始支持，Oracle 7 开始支持。 其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段： 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是 否可以提交. 第二阶段：事务协调器要求每个数据库提交数据。 其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务 中的那部分信息。 XA 协议比较简单，而且一旦商业数据库实现了 XA 协议，使用分布式事务的成本也比较 低。 XA 性能不理想，特别是在交易下单链路，往往并发量很高，XA 无法满足高并发场景 XA 目前在商业数据库支持的比较理想，在 mysql 数据库中支持的不太理想，mysql 的 XA 实现，没有记录 prepare 阶段日志，主备切换回导致主库与备库数据不一致。 许多 nosql 也没有支持 XA，这让 XA 的应用场景变得非常狭隘。 也有 3PC，引入了超时机制（无论协调者还是参与者，在向对方发送请求后，若长时间 未收到回应则做出相应处理） 柔性事务 TCC 事务补偿型方案刚性事务：遵循 ACID 原则，强一致性。 柔性事务：遵循 BASE 理论，最终一致性； 与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。 柔性事务 最大努力通知方案按规律进行通知，不保证数据一定能通知成功，但会提供可查询操作接口进行核对。这种 方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。这种 方案也是结合 MQ 进行实现，例如：通过 MQ 发送 http 请求，设置最大通知次数。达到通 知次数后即不再通知。 案例：银行通知、商户通知等（各大交易业务平台间的商户通知：多次通知、查询校对、对 账文件），支付宝的支付成功异步回调 柔性事务 + 可靠消息 + 最终一致性实现：业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只 记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确 认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。 seata 每一个服务创建数据表 undo_log 安装事务协调器：seata-server : http://github.com/seata/seata/releases 整合 1）导入依赖 spring-cloud-starter-alibaba-seata 2）解压并启动seata-server： ​ Registry.conf: 注册中心配置 3）配置代理数据源 4）每个微服务导入 registry.conf file.conf vgroup_mapping.{application.name}-fescar-service-group &#x3D; “default” ​ 5) 加globaTransactional","categories":[],"tags":[]},{"title":"接口幂等性","slug":"接口幂等性","date":"2022-08-10T02:00:00.000Z","updated":"2022-08-11T14:06:32.123Z","comments":true,"path":"2022/08/10/接口幂等性/","link":"","permalink":"http://duanyushuai.github.io/2022/08/10/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7/","excerpt":"","text":"接口幂等性问题出现 用户多次点击 用户回退在提交 feign触发重试 1.token token 的获取、比较和删除必须是原子性的 使用redis和lua脚本 1if redis.call(&#x27;get&#x27;,KEYS[1]== ARGV[1] then return is.call(&#x27;del&#x27;,KEYS[1])) else return 0 end 2. 各种锁机制1. 数据库悲观锁1select * from xxxx where id=1 for update id一定是主键和唯一索引，不然可能造成锁表 2. 数据库乐观锁首先获取这条数据的版本号version，然后操作的时候带上版本号 1update goods set count = count -1 ,version = version + 1 where id = 2 and version = 1 乐观锁处理读多写少问题 3. 业务分布式锁4. 各种唯一索引数据库的唯一约束插入数据按照唯一索引，比如订单号，相同的订单号就不能重复插入。需要不是自增主键，代码生成全局唯一id。 在分库分表下，根据路由规则，要路由到同一张表，才能是唯一索引有意义。 redis防重我们可以计算上传数据的MD5值，存到redis set，每次处理数据，去和redis进行匹配 防重表把orderNo作为去重表的唯一索引插入mysql，去重表和业务表处在同一数据库，处于同一事务，方便回滚 5.全局请求唯一id调用接口生成唯一id，保存在redis的集合中。 可以使用nginx设置请求的唯一id 1proxy_set_header X-Request-Id $request_id;","categories":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/categories/java-web/"}],"tags":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/tags/java-web/"}]},{"title":"redis 缓存","slug":"redis 缓存","date":"2022-07-11T13:46:55.260Z","updated":"2022-07-12T13:52:10.751Z","comments":true,"path":"2022/07/11/redis 缓存/","link":"","permalink":"http://duanyushuai.github.io/2022/07/11/redis%20%E7%BC%93%E5%AD%98/","excerpt":"","text":"redis 缓存那些数据适合缓存 即时性和数据一致性要求不高的 读多写少 使用redis 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 简单的分布式锁 12345678910111213141516171819202122232425262728293031323334353637383940public Map&lt;String, List&lt;Catelog2Vo&gt;&gt; getCatalogJsonFromDbWithRedislock() &#123; // 1 占分布式锁，去redis占坑 String uuid = UUID.randomUUID().toString(); Boolean lock = redisTemplate.opsForValue().setIfAbsent(&quot;lock&quot;, uuid, 300, TimeUnit.SECONDS); if (lock) &#123; System.out.println(&quot;获取分布式锁成功&quot;); // 加锁成功...执行业务 // 2 设置过期时间// redisTemplate.expire(&quot;lock&quot;, 30, TimeUnit.SECONDS); Map&lt;String, List&lt;Catelog2Vo&gt;&gt; dataFromDB; try &#123; dataFromDB = getDataFromDB(); &#125; finally &#123; String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == ARGV[1] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; // 删除锁 Long lock1 = redisTemplate.execute(new DefaultRedisScript&lt;Long&gt;(script, Long.class), Arrays.asList(&quot;lock&quot;), uuid); &#125;// redisTemplate.delete(&quot;lock&quot;); // 获取值对比 + 对比成功删除 = 原子操作 lua脚本解锁// String lockValue = redisTemplate.opsForValue().get(&quot;lock&quot;);// if (uuid.equals(lockValue)) &#123;// // 删除我自己的锁// redisTemplate.delete(&quot;lock&quot;);// &#125; return dataFromDB; &#125; else &#123; // 加锁失败 // 休眠100ms重试 System.out.println(&quot;获取分布式锁失败...等待重试&quot;); try &#123; Thread.sleep(200); &#125; catch (Exception e) &#123; &#125; return getCatalogJsonFromDbWithRedislock(); // 自旋的方式 &#125; &#125;","categories":[],"tags":[]},{"title":"nginx使用","slug":"nginx使用","date":"2022-07-02T10:30:26.308Z","updated":"2023-02-22T06:14:09.393Z","comments":true,"path":"2022/07/02/nginx使用/","link":"","permalink":"http://duanyushuai.github.io/2022/07/02/nginx%E4%BD%BF%E7%94%A8/","excerpt":"","text":"nginx使用nginx目录1234conf 配置文件sbin 启动程序logs 日志html 默认页 配置文件 12345678910111213141516171819202122232425262728293031323334353637worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; # mine.types 告诉浏览器怎么解析数据 default_type application/octet-stream; sendfile on; //零拷贝 #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; # 域名 location / &#123; root html; # nginx目录 index index.html index.htm; # 默认页 &#125; # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 反向代理 负载均衡12345678910111213141516171819202122232425262728293031323334353637 worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; # mine.types 告诉浏览器怎么解析数据 default_type application/octet-stream; sendfile on; //零拷贝 keepalive_timeout 65; #gzip on; upstream httpds &#123; server 192.168.444.102:80; server 192.168.444.103:80; &#125; server &#123; listen 80; server_name localhost; # 域名 proxy_pass http://httpds; # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 动静分离12345678910111213141516171819202122232425262728293031323334353637worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; # mine.types 告诉浏览器怎么解析数据 default_type application/octet-stream; sendfile on; //零拷贝 keepalive_timeout 65; &#125; server &#123; listen 80; server_name localhost; # 域名 location / &#123; # 优先级低 proxy_pass http://120.23.34.23:8080; &#125; location ~*/(js|img|css)&#123; root html index index.html index.htm; &#125; # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; url writehttp:120.32.12.123/index.jsp?pageNum=1 -&gt; http:120.32.12.123/2.html 123456789101112131415161718192021server &#123; listen 80; server_name localhost; # 域名 location / &#123; # 优先级低 rewrite ^/2.html$ index.jsp?pageNum=2 proxy_pass http://120.23.34.23:8080; &#125; location ~*/(js|img|css)&#123; root html index index.html index.htm; &#125; # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; 防盗链配置1valid_referers none | blocked | server_names | strings ... 请求头有refer，二次请求资源 在需要location中配置 123456789 valid_referers 192.168.44.101; #允许 if ($invalid_referer)&#123; return 403;&#125;valid_referers none 192.168.44.101; #允许无refer和包含192.168.44.101if ($invalid_referer)&#123; return 403;&#125; 高可用keeplive","categories":[],"tags":[]},{"title":"sku和spu数据库设计","slug":"sku和spu数据库设计","date":"2022-06-26T10:50:48.206Z","updated":"2022-07-03T02:56:31.206Z","comments":true,"path":"2022/06/26/sku和spu数据库设计/","link":"","permalink":"http://duanyushuai.github.io/2022/06/26/sku%E5%92%8Cspu%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"sku和spu数据库设计","categories":[],"tags":[]},{"title":"自定义注解","slug":"自定义注解（校验和日志）","date":"2022-06-26T03:34:51.020Z","updated":"2022-07-02T07:51:02.580Z","comments":true,"path":"2022/06/26/自定义注解（校验和日志）/","link":"","permalink":"http://duanyushuai.github.io/2022/06/26/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3%EF%BC%88%E6%A0%A1%E9%AA%8C%E5%92%8C%E6%97%A5%E5%BF%97%EF%BC%89/","excerpt":"","text":"自定义注解（校验和日志）JSR303 自定义校验创建ListValue校验注解123456789101112131415161718192021222324252627package com.yxj.gulimall.common.valid;import javax.validation.Constraint;import javax.validation.Payload;import java.lang.annotation.*;/** * * 自定义校验注解 */@Documented@Constraint( validatedBy = &#123;ListValueConstraintValidator.class&#125;)@Target(&#123;ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER, ElementType.TYPE_USE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface ListValue &#123; String message() default &quot;&#123;com.chenxin.gulimail.common.valid.ListValue.message&#125;&quot;; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; int[] vals() default &#123;&#125;;&#125; ListValueConstraintValidator校验器1234567891011121314151617181920212223242526&#123; Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); /** * 初始化 * @param constraintAnnotation */ @Override public void initialize(ListValue constraintAnnotation) &#123; int[] vals = constraintAnnotation.vals(); for (int val : vals) &#123; set.add(val); &#125; &#125; /** * 真正的校验规则 * 判断是否校验成功 * @param integer * @param constraintValidatorContext * @return */ @Override public boolean isValid(Integer integer, ConstraintValidatorContext constraintValidatorContext) &#123; return set.contains(integer); &#125;&#125;","categories":[],"tags":[]},{"title":"redis Guava 缓存","slug":"redis-Guava-缓存","date":"2022-06-26T02:00:00.000Z","updated":"2022-07-24T13:18:01.257Z","comments":true,"path":"2022/06/26/redis-Guava-缓存/","link":"","permalink":"http://duanyushuai.github.io/2022/06/26/redis-Guava-%E7%BC%93%E5%AD%98/","excerpt":"","text":"redis Guava 缓存redis 懒加载数据在新增到 MySQL 不进行缓存，在精确查找进行缓存，做到查询即缓存，不查询不缓存。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// 伪代码示例 Xx代表你的的业务对象 如User Goods等等public class XxLazyCache &#123; @Autowired private RedisTemplate&lt;String, Xx&gt; redisTemplate; @Autowired private XxService xxService;// 你的业务service /** * 查询 通过查询缓存是否存在驱动缓存加载 建议在前置业务保证id对应数据是绝对存在于数据库中的 */ public Xx getXx(int id) &#123; // 1.查询缓存里面有没有数据 Xx xxCache = getXxFromCache(id); if(xxCache != null) &#123; return xxCache;// 卫语句使代码更有利于阅读 &#125; // 2.查询数据库获取数据 我们假定到业务这一步，传过来的id都在数据库中有对应数据 Xx xx = xxService.getXxById(id); // 3.设置缓存、这一步相当于Redis缓存懒加载，下次再查询此id，则会走缓存 setXxFromCache(xx); return xx; &#125; &#125; /** * 对xx数据进行修改或者删除操作 操作数据库成功后 删除缓存 * 删除请求 - 删除数据库数据 删除缓存 * 修改请求 - 更新数据库数据 删除缓存 下次在查询时候就会从数据库拉取新的数据到缓存中 */ public void deleteXxFromCache(long id) &#123; String key = &quot;Xx:&quot; + xx.getId(); redisTemplate.delete(key); &#125; private void setXxFromCache(Xx xx) &#123; String key = &quot;Xx:&quot; + xx.getId(); redisTemplate.opsForValue().set(key, xx); &#125; private Xx getXxFromCache(int id) &#123; // 通过缓存前缀拼装唯一主键作为缓存Key 如Xxx信息 就是Xxx:id String key = &quot;Xx:&quot; + id; return redisTemplate.opsForValue().get(key); &#125;&#125;// 业务类public class XxServie &#123; @Autowired private XxLazyCache xxLazyCache; // 查询数据库 public Xx getXxById(long id) &#123; // 省略实现 return xx; &#125; public void updateXx(Xx xx) &#123; // 更新MySQL数据 省略 // 删除缓存 xxLazyCache.deleteXxFromCache(xx.getId()); &#125; public void deleteXx(long id) &#123; // 删除MySQL数据 省略 // 删除缓存 xxLazyCache.deleteXxFromCache(xx.getId()); &#125;&#125;// 实体类@Datapublic class Xx &#123; // 业务主键 private Long id; // ...省略&#125;","categories":[{"name":"Guava","slug":"Guava","permalink":"http://duanyushuai.github.io/categories/Guava/"},{"name":"redis","slug":"Guava/redis","permalink":"http://duanyushuai.github.io/categories/Guava/redis/"}],"tags":[{"name":"Guava","slug":"Guava","permalink":"http://duanyushuai.github.io/tags/Guava/"},{"name":"redis","slug":"redis","permalink":"http://duanyushuai.github.io/tags/redis/"}]},{"title":"解决跨域","slug":"解决跨域","date":"2022-06-25T09:57:38.465Z","updated":"2022-08-14T04:28:49.153Z","comments":true,"path":"2022/06/25/解决跨域/","link":"","permalink":"http://duanyushuai.github.io/2022/06/25/%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F/","excerpt":"","text":"解决跨域 使用nginx部署为同一域 请求返回可跨域","categories":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/categories/java-web/"}],"tags":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/tags/java-web/"}]},{"title":"api接口优化","slug":"api接口优化","date":"2022-06-07T02:00:00.000Z","updated":"2022-08-14T04:29:34.848Z","comments":true,"path":"2022/06/07/api接口优化/","link":"","permalink":"http://duanyushuai.github.io/2022/06/07/api%E6%8E%A5%E5%8F%A3%E4%BC%98%E5%8C%96/","excerpt":"","text":"api 接口调优慢查询1.深度分页1select name,code from student limit 1000,20 会查出来前1000条数据 1select name,code from student where id &gt; 1000 limit 20 走索引，但需要上次查询出来的最大id 2.未加索引1show create table xxxx (表名) 查看表索引 加索引表可能引起锁表，要在mysql使用低峰期 3.索引失效索引失效的几个原因 索引字段的区分度不大 索引语句在or中 模糊匹配 %xxx 索引发生隐式变换 不满足最左前缀规则 where条件里，索引有计算 4.join 过多or子查询过多一般不建议用子查询，可以把子查询改成join，join的表也不宜过多，具体问题具体分析，看数据量 5.in的元素过多如果一个查询有in ，in条件加了合适的索引，还是慢，就高度怀疑是in的元素过多。可以分组查询，再快可以引用多线程 in元素过多可以在代码层做限制 123if(ids.size() &gt; 200) &#123; throw new Exception(&quot;单次查询数据量太多&quot;)&#125; 6.单纯数据量过大分库分表 业务复杂1.循环调用循环调用同一段代码，每次的循环逻辑一致，前后不关联。比如我们要初始化一个列表。 可采用多线程的方式去获取数据 2. 顺序调用 使用CompletableFuture解决 3. 线程池设置不合理调整线程池参数，查看时候是io任务还是cpu任务，根据业务来拆分线程池。 4. 锁设置并不合理锁类型使用不合理，就是读写锁。锁粒度太大 5.机器问题（fullGC，机器重启，线程打满）造成这个问题的原因非常多，笔者就遇到了定时任务过大引起fullGC，代码存在线程泄露引起RSS内存占用过高进而引起机器重启等待诸多原因。需要结合各种监控和具体场景具体分析，进而进行大事务拆分、重新规划线程池等等工作 6. 万金油解决方式 缓存 简单的map guava等本地缓存工具包 缓存中间件：redis、tair或memcached 回调和反查 ​ 这种方式往往是业务上的解决方式，在订单或者付款系统中应用的比较多。举个例子：当我们付款的时候，需要调用一个专门的付款系统接口，该系统经过一系列验证、存储工作后还要调用银行接口以执行付款。由于付款这个动作要求十分严谨，银行侧接口执行可能比较缓慢，进而拖累整个付款接口性能。 ​ 这个时候我们就可以采用fast success的方式：当必要的校验和存储完成后，立即返回success，同时告诉调用方一个中间态“付款中”。而后调用银行接口，当获得支付结果后再调用上游系统的回调接口返回付款的最终结果“成果”or“失败”。","categories":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/categories/java-web/"}],"tags":[{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/tags/java-web/"}]},{"title":"二分查找","slug":"二分查找","date":"2022-04-22T02:00:00.000Z","updated":"2022-11-03T09:31:31.148Z","comments":true,"path":"2022/04/22/二分查找/","link":"","permalink":"http://duanyushuai.github.io/2022/04/22/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","excerpt":"","text":"二分查找&#x2F;排序1. 二分查找12345678910111213141516171819202122232425262728import java.util.*;public class Solution &#123; /** * 代码中的类名、方法名、参数名已经指定，请勿修改，直接返回方法规定的值即可 * * * @param nums int整型一维数组 * @param target int整型 * @return int整型 */ public int search (int[] nums, int target) &#123; int l = 0; int r = nums.length - 1; while (l &lt;= r) &#123; int m = (l + r) / 2; if (nums[m] == target) &#123; return m; &#125; if (nums[m] &gt; target) r = m - 1; else l = m + 1; &#125; return -1; &#125;&#125; 2. 归并排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Sort &#123; public static void MergeSort(int[] arr, int low, int high) &#123; //使用递归的方式进行归并排序，所需要的空间复杂度是O（N+logN） int mid = (low + high)/2; if(low &lt; high) &#123; //递归地对左右两边进行排序 MergeSort(arr, low, mid); MergeSort(arr, mid+1, high); //合并 merge(arr, low, mid, high); &#125; &#125; //merge函数实际上是将两个有序数组合并成一个有序数组 //因为数组有序，合并很简单，只要维护几个指针就可以了 private static void merge(int[] arr, int low, int mid, int high) &#123; //temp数组用于暂存合并的结果 int[] temp = new int[high - low + 1]; //左半边的指针 int i = low; //右半边的指针 int j = mid+1; //合并后数组的指针 int k = 0; //将记录由小到大地放进temp数组 for(; i &lt;= mid &amp;&amp; j &lt;= high; k++) &#123; if(arr[i] &lt; arr[j]) temp[k] = arr[i++]; else temp[k] = arr[j++]; &#125; //接下来两个while循环是为了将剩余的（比另一边多出来的个数）放到temp数组中 while(i &lt;= mid) temp[k++] = arr[i++]; while(j &lt;= high) temp[k++] = arr[j++]; //将temp数组中的元素写入到待排数组中 for(int l = 0; l &lt; temp.length; l++) arr[low + l] = temp[l]; &#125; &#125; 3.快速排序123456789101112131415161718192021222324252627282930313233343536373839public class QuickSort implements IArraySort &#123; @Override public int[] sort(int[] sourceArray) throws Exception &#123; // 对 arr 进行拷贝，不改变参数内容 int[] arr = Arrays.copyOf(sourceArray, sourceArray.length); return quickSort(arr, 0, arr.length - 1); &#125; private int[] quickSort(int[] arr, int left, int right) &#123; if (left &lt; right) &#123; int partitionIndex = partition(arr, left, right); quickSort(arr, left, partitionIndex - 1); quickSort(arr, partitionIndex + 1, right); &#125; return arr; &#125; private int partition(int[] arr, int left, int right) &#123; // 设定基准值（pivot） int pivot = left; int index = pivot + 1; for (int i = index; i &lt;= right; i++) &#123; if (arr[i] &lt; arr[pivot]) &#123; swap(arr, i, index); index++; &#125; &#125; swap(arr, pivot, index - 1); return index - 1; &#125; private void swap(int[] arr, int i, int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://duanyushuai.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://duanyushuai.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"docker入门","slug":"docker","date":"2022-03-02T02:00:00.000Z","updated":"2023-03-06T02:57:23.907Z","comments":true,"path":"2022/03/02/docker/","link":"","permalink":"http://duanyushuai.github.io/2022/03/02/docker/","excerpt":"","text":"docker1234567891011121314151617181920212223242526272829301. 卸载系统之前的docker sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine2.$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm23. sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 4. 安装DOCKER引擎sudo yum install docker-ce docker-ce-cli containerd.io5. 启动Docker.sudo systemctl start docker6. 设置开机自启sudo systemctl start docker7. 阿里云镜像加速器https://cr.console.aliyun.com/cn-wulanchabu/instances/mirrors docker 使用123456789101112131415161718192021222324252627282930313233343536373839404142434445sudo docker pull mysql:8.0docker images创建目录保存数据sudo docker run --name mysql -v /usr/local/mysql/data:/var/lib/mysql -v /usr/local/mysql:/etc/mysql/conf.d -v /usr/local/mysql/log:/var/log/mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:8.0## -v 目录映射，可以在linux环境中寻找文件，修改容器配置查看运行容器docker ps[root@hecs-328722 mysql]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES369ccdfb7630 mysql:8.0 &quot;docker-entrypoint.s…&quot; 6 minutes ago Up 6 minutes 0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp, 33060/tcp mysql进入容器 内部docker exec -it 容器名称|容器id bin/bashdocker exec -it mysql bin/bash退出容器exit1. 安装redisdocker pull redis:6.0.102. 修改需要自定义的配置(docker-redis默认没有配置文件，自己在宿主机建立后挂载映射)创建并修改/usr/local/redis/redis.confbind 0.0.0.0 开启远程权限appendonly yes 开启aof持久化3.docker run --name redis -v /usr/local/redis/data:/data -v /usr/local/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis:6.0.10 redis-server /usr/local/etc/redis/redis.conf 解释： -v /usr/local/redis/data:/data # 将数据目录挂在到本地保证数据安全 -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf # 将配置文件挂在到本地修改方便 4. docker 起客户端 docker exec -it redis redis-cli 5. 重启redis docker restart redis 123docker diff [容器名]docker commit 提交容器更改的 Docker 挂载三种挂载方式 docker 自动在外部处创建文件夹自动挂载容器内部制定的文件夹内容[dockerfile VOLUME 指令的作用] 自己在外部创建文件夹，手动挂载 可以把数据挂载到内存中 –mount 挂载到linux宿主机（不怎么用） -v 可以自动挂载 1、volume(卷) 匿名卷使用 1docker run -dP -v :/etc/nginx nginx 具名卷使用 123docker run -dP -v nginx:/etc/nginx nginx# docker 将创建名为nginx卷，并保存容器/etc/nginx下面的内容 -v 宿主机绝对路径：docker 容器内部绝对路径 叫挂载 -v 不以&#x2F;开头的路径：docker容器内绝对路径 叫绑定（docker 会自动管理，docker不会把他当成目录） -v 挂载小心映射空目录 -v html:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; docker inspect 容器的信息。 docker自动管理模式 1234567891011121314# 可以看到&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, //卷 &quot;Name&quot;: &quot;html&quot;, //名字叫html &quot;Source&quot;: &quot;/var/lib/docker/volumes/html/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, //读写模式 &quot;Propagation&quot;: &quot;&quot; &#125; ] -v &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html; 效果：匿名卷 （什么也不写也不加冒号，直接写容器内目录） 1docker volume 可以对卷进行操作 1234567891011# 一行命令启动nginx，并且配置文件和html页面。需要知道卷的位置docker run -d -P nginxconf:/etc/nginx/ -v nginxpage:/usr/share/nginx/html nginx# 想要实现 docker run -d -P -v /root/nginxconf:/etc/nginx/ -v /root/nginxhtml:/usr/share/nginx/html --name=nginx000 nginx### 提前准备好东西，再调用命令### 随便启动个nginx，复制出内容 ### docker cp nginxdemo:/etc/nginx. /root/nginxconf### ocker run -d -P -v /root/nginxconf:/etc/nginx/ -v /root/nginxhtml:/usr/share/nginx/html --name=nginx000 nginx docker 网络1","categories":[{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/categories/docker/"},{"name":"谷粒商城","slug":"docker/谷粒商城","permalink":"http://duanyushuai.github.io/categories/docker/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/tags/docker/"}]},{"title":"视频工具","slug":"工具","date":"2022-02-22T02:00:00.000Z","updated":"2022-08-28T06:39:49.980Z","comments":true,"path":"2022/02/22/工具/","link":"","permalink":"http://duanyushuai.github.io/2022/02/22/%E5%B7%A5%E5%85%B7/","excerpt":"","text":"工具你有没有想过，在自己常用的网站地址前加几个字符，就可以实现各种各样的效果？ 无需安装任何软件，就能解析视频、下载音乐、复制文库……是的你没看错，只需要简单地添加一个前缀，就能解决。 视频解析 找到你喜欢的电影&#x2F;电视剧，打开它所在当前网页。 不论是爱奇艺，腾讯视频还是其他视频网站，只需要在网站前加上wn.run&#x2F;这串字符。 注意：一定要在http或https前面添加。 然后按下回车，就会跳转至一个名为万能命令的新页面。 在下方【相关视频播放】这一栏里，就是你想观看的视频的解析结果。 任选一个解析网站打开，就可以全屏观看该视频了。 文库下载 对于工作党和学生党来说，最痛苦的事情，莫过于找到了急需的资料，却没有文库VIP了。 在某度文库上，如果没有开通VIP的话，既无法复制文字，也无法下载文档，几乎是寸步难行。 这时候，我们只需要在所需文档地址前加上wn.run&#x2F;前缀。 按下回车，就可以找到文库在线下载的解析结果了。 点击上述结果，即会自动跳转至一个名为网页转换助手的页面。 在这里，你可以选择【转为Word】或【转为PDF】。 然后点击【下载】按钮，就能成功下载该会员文档的源文件了。 音乐下载 如果想要下载网易云音乐、QQ音乐、酷狗音乐上的歌曲，只需在播放地址前加上wn.run&#x2F;。 然后选择其中一个解析源，就能下载歌曲了。 视频下载 当然，这个小技巧不仅能用于下载音乐，同时也可以用来下载各个视频网站上的视频。 以B站为例，在网址前输入wn.run&#x2F;。 然后回车，选择其中一个解析结果，就可以成功下载该视频了。 除了上面介绍的功能，通过wn.run&#x2F;这个命令还能实现许许多多的效果，比如网页翻译、网页截图、网页二维码生成等等。 每个功能都无需下载、即用即走，且没有平台限制，pc、android、ios等都可使用。 另外，在万能命令网站里，还收录了很多高质量的工具，大家感兴趣的话，也可以直接收藏这个地址。 鉴于这个工具比较敏感，如果大家有需要的话，就赶紧试试吧！","categories":[{"name":"工具","slug":"工具","permalink":"http://duanyushuai.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://duanyushuai.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"rabbitMQ","slug":"rabbitMQ","date":"2022-02-20T02:00:00.000Z","updated":"2023-01-16T09:30:53.049Z","comments":true,"path":"2022/02/20/rabbitMQ/","link":"","permalink":"http://duanyushuai.github.io/2022/02/20/rabbitMQ/","excerpt":"","text":"rabbitMQhttps://www.rabbitmq.com/getstarted.html 用途 流量消峰 应用接偶 异步处理 交换机三种类型Fanout：广播，将消息交给所有绑定到交换机的队列消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.duan.config;import com.rabbitmq.client.*;import java.io.IOException;public class ConsumerFanout1 &#123; public static void main(String[] args) throws Exception&#123; //1.创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //2.设定参数 ip地址 factory.setHost(&quot;124.70.99.112&quot;); factory.setVirtualHost(&quot;/&quot;); factory.setPort(5672); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); //3.创建连接 Connection Connection connection = factory.newConnection(); //4.创建Channel Channel channel = connection.createChannel(); //5.创建队列Queue // 参数String queue名称 没有自动创建 // boolean durable 是否持久化 // boolean exclusive 是否独占 连接关闭后是否删除队列 // boolean autoDelete 没有Consumer时 自动删除 // Map&lt;String, Object&gt; arguments 参数信息 //6.接收消息 // String queue 队列名称 // boolean autoAck 是否自动确认 // Consumer callback 回调对象 Consumer consumer = new DefaultConsumer(channel)&#123; //收到消息后的回调方法 //consumerTag 消息标识 //envelope 获取交换机 路由等信息 //body 数据 @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;consumerTag:&quot;+consumerTag); System.out.println(&quot;Exchange:&quot;+envelope.getExchange()); System.out.println(&quot;RoutingKey:&quot;+envelope.getRoutingKey()); System.out.println(&quot;properties:&quot;+properties); System.out.println(&quot;body:&quot;+new String(body)); System.out.println(&quot;将日志信息打印到控制台&quot;); &#125; &#125;; channel.basicConsume(&quot;test_fanout_queue1&quot;,true,consumer); &#125;&#125; 生产者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.duan.config;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;public class ProducerFanout &#123; public static void main(String[] args) throws Exception&#123; //1.创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //2.设定参数 ip地址 factory.setHost(&quot;124.70.99.112&quot;); factory.setPort(5672); factory.setVirtualHost(&quot;/&quot;); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); //3.创建连接 Connection Connection connection = factory.newConnection(); //4.创建Channel Channel channel = connection.createChannel(); //5.创建交换机 // String exchange 交换机名称 // BuiltinExchangeType type 交换机类型 // boolean durable 是否持久化 // boolean autoDelete 是否自动删除 // boolean internal : 一般false // Map&lt;String, Object&gt; arguments：参数列表 String exchangeName = &quot;test_fanout&quot;; channel.exchangeDeclare(exchangeName, BuiltinExchangeType.FANOUT,true,false,false,null); //6.创建队列 String queueName1 = &quot;test_fanout_queue1&quot;; String queueName2 = &quot;test_fanout_queue2&quot;; channel.queueDeclare(queueName1,true,false,false,null); channel.queueDeclare(queueName2,true,false,false,null); //7.绑定队列和交换机 // String queue: 队列名称 // String exchange 交换机名称 // String routingKey 路由键，绑定规则 (fanout类型 路由规则为空，分发给每一个绑定的queue) // Map&lt;String, Object&gt; arguments channel.queueBind(queueName1,exchangeName,&quot;&quot;); channel.queueBind(queueName2,exchangeName,&quot;&quot;); //8.发送消息 String body = &quot;log: findAll() method is called!!&quot;; channel.basicPublish(exchangeName,&quot;&quot;,null,body.getBytes()); //9.释放资源 channel.close(); connection.close(); &#125;&#125; direct 直接交换机topic 交换机routing_key 必须是一个单词列表，以点号隔开 *可以代替一个单词 #可以替代零个和多个单词 123456789101112131415161718//1.创建连接工厂 ConnectionFactory factory = new ConnectionFactory(); //2.设定参数 ip地址 factory.setHost(&quot;124.70.99.112&quot;); factory.setVirtualHost(&quot;/&quot;); factory.setPort(5672); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); //3.创建连接 Connection Connection connection = factory.newConnection(); //4.创建Channel Channel channel = connection.createChannel(); channel.exchangeDeclare(&quot;topic_test&quot;,BuiltinExchangeType.TOPIC); channel.queueDeclare(&quot;Q1&quot;,false,false,false,null); channel.queueBind(&quot;Q1&quot;,&quot;topic_test&quot;,&quot;*.orange.*&quot;); channel.basicConsume(&quot;Q1&quot;,true,(consumerTag,message)-&gt;&#123; System.out.println(new String(message.getBody(), StandardCharsets.UTF_8)); &#125;,(consumerTag -&gt; &#123;&#125;)); 12345678910111213//1.创建连接工厂ConnectionFactory factory = new ConnectionFactory();//2.设定参数 ip地址factory.setHost(&quot;124.70.99.112&quot;);factory.setVirtualHost(&quot;/&quot;);factory.setPort(5672);factory.setUsername(&quot;guest&quot;);factory.setPassword(&quot;guest&quot;);//3.创建连接 ConnectionConnection connection = factory.newConnection();//4.创建ChannelChannel channel = connection.createChannel();channel.basicPublish(&quot;topic_test&quot;,&quot;#&quot;,null,&quot;hahaha&quot;.getBytes(StandardCharsets.UTF_8)); 延迟队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//配置@Configurationpublic class TtlQueueConfig &#123; public static final String X_EXCHANG = &quot;X&quot;; public static final String Y_DEAD_EXCHANGE = &quot;Y&quot;; public static final String QUEUE_A = &quot;QA&quot;; public static final String QUEUE_B = &quot;QB&quot;; public static final String DEAD_QUEUE = &quot;QD&quot;; @Bean(&quot;xExchange&quot;) public DirectExchange xExchange()&#123; return new DirectExchange(X_EXCHANG); &#125; @Bean(&quot;yExchange&quot;) public DirectExchange yExchange()&#123; return new DirectExchange(Y_DEAD_EXCHANGE); &#125; @Bean(&quot;queueA&quot;) public Queue queueA()&#123; Map&lt;String,Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(&quot;x-dead-letter-exchange&quot;,Y_DEAD_EXCHANGE); arguments.put(&quot;x-dead-letter-routing-key&quot;,&quot;YD&quot;); arguments.put(&quot;x-message-ttl&quot;,10000); return QueueBuilder.durable(QUEUE_A).withArguments(arguments).build(); &#125; @Bean(&quot;queueB&quot;) public Queue queueB()&#123; Map&lt;String,Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(&quot;x-dead-letter-exchange&quot;,Y_DEAD_EXCHANGE); arguments.put(&quot;x-dead-letter-routing-key&quot;,&quot;YD&quot;); arguments.put(&quot;x-message-ttl&quot;,40000); return QueueBuilder.durable(QUEUE_B).withArguments(arguments).build(); &#125; @Bean(&quot;queueD&quot;) public Queue queueD()&#123; return QueueBuilder.durable(DEAD_QUEUE).build(); &#125; @Bean public Binding queueABindingX(@Qualifier(&quot;queueA&quot;)Queue queueA,@Qualifier(&quot;xExchange&quot;) DirectExchange xExchange)&#123; return BindingBuilder.bind(queueA).to(xExchange).with(&quot;XA&quot;); &#125; @Bean public Binding queueBBindingY(@Qualifier(&quot;queueB&quot;) Queue queueB,@Qualifier(&quot;xExchange&quot;) DirectExchange xExchange)&#123; return BindingBuilder.bind(queueB).to(xExchange).with(&quot;XB&quot;); &#125; @Bean public Binding queueDBindingYD(@Qualifier(&quot;queueD&quot;) Queue queueD,@Qualifier(&quot;yExchange&quot;) DirectExchange yExchange)&#123; return BindingBuilder.bind(queueD).to(yExchange).with(&quot;YD&quot;); &#125;&#125; 123456789//消费者@Componentpublic class TtlComsumer &#123; @RabbitListener(queues = &quot;QD&quot;) public void receiveD(Message message, Channel channel)&#123; System.out.println(&quot;消息:&quot;+new String(message.getBody())); &#125;&#125; 123456789101112//生产者public class SendMsg &#123; @Autowired private RabbitTemplate rabbitTemplate; @GetMapping(&quot;/sendMsg/&#123;message&#125;&quot;) public void sendMsg(@PathVariable String message)&#123; rabbitTemplate.convertAndSend(&quot;X&quot;,&quot;XA&quot;,&quot;消息来自10s,&quot;+message); rabbitTemplate.convertAndSend(&quot;X&quot;,&quot;XB&quot;,&quot;消息来自40s,&quot;+message); &#125;&#125; 有人问：如果每个消息过期时间不一样，在队列里前置消息没过期，后置消息过期了，后置消息进不了过期队列，怎么解决解决这个问题 答：利用延迟交换机插件（用到在学） 修改bug数量2个 开通biyi账号4个 开会沟通后期开发内容 协助测试网格化小程序app pc端，完成80%","categories":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"http://duanyushuai.github.io/categories/rabbitMQ/"}],"tags":[{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"http://duanyushuai.github.io/tags/rabbitMQ/"}]},{"title":"全局异常","slug":"全局异常","date":"2021-10-11T02:00:00.000Z","updated":"2022-08-14T04:29:18.719Z","comments":true,"path":"2021/10/11/全局异常/","link":"","permalink":"http://duanyushuai.github.io/2021/10/11/%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8/","excerpt":"","text":"全局异常12345678910111213141516171819202122@Slf4j@RestControllerAdvice(basePackages = &quot;com.yxj.gulimall.product.controller&quot;)public class GulimallExceptionControllerAdvice &#123; @ExceptionHandler(value = MethodArgumentNotValidException.class) public R handleValidException(MethodArgumentNotValidException e) &#123; log.error(&quot;数据校验出现问题&#123;&#125;,异常类型: &#123;&#125;&quot;,e.getMessage(),e.getClass()); BindingResult bindingResult = e.getBindingResult(); Map&lt;String, String&gt; errorMap = new HashMap&lt;&gt;(); bindingResult.getFieldErrors().forEach((fieldError -&gt; &#123; errorMap.put(fieldError.getField(),fieldError.getDefaultMessage()); &#125;)); return R.error(BizCodeEnum.VALID_EXCEPTION.getCode(),BizCodeEnum.VALID_EXCEPTION.getMsg()).put(&quot;data&quot;,errorMap); &#125; @ExceptionHandler(value = Throwable.class) public R handleException(Throwable throwable) &#123; log.error(&quot;错误:&quot;, throwable); return R.error(BizCodeEnum.UNKNOWN_EXCEPTION.getCode(),BizCodeEnum.UNKNOWN_EXCEPTION.getMsg()); &#125;&#125;","categories":[],"tags":[]},{"title":"HashMap","slug":"HashMap","date":"2021-07-08T03:00:23.000Z","updated":"2022-06-18T07:38:31.348Z","comments":true,"path":"2021/07/08/HashMap/","link":"","permalink":"http://duanyushuai.github.io/2021/07/08/HashMap/","excerpt":"","text":"HashMapjdk1.7 数组+链表 jdk1.8 数组+ 链表&#x2F;红黑树 DEFAULT_INITIAL_CAPACITY Table数组的初始化长度： 1 &lt;&lt; 4``2^4=16（为什么要是 2的n次方？） MAXIMUM_CAPACITY Table数组的最大长度： 1&lt;&lt;30``2^30=1073741824 DEFAULT_LOAD_FACTOR 负载因子：默认值为0.75。 当元素的总个数&gt;当前数组的长度 * 负载因子。数组会进行扩容，扩容为原来的两倍（todo：为什么是两倍？） TREEIFY_THRESHOLD 链表树化阙值： 默认值为 8 。表示在一个node（Table）节点下的值的个数大于8时候，会将链表转换成为红黑树。 UNTREEIFY_THRESHOLD 红黑树链化阙值： 默认值为 6 。 表示在进行扩容期间，单个Node节点下的红黑树节点的个数小于6时候，会将红黑树转化成为链表。 MIN_TREEIFY_CAPACITY = 64 最小树化阈值，当Table所有元素超过改值，才会进行树化（为了防止前期阶段频繁扩容和树化过程冲突） HashMap是线程不安全的","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"},{"name":"HashMap","slug":"HashMap","permalink":"http://duanyushuai.github.io/tags/HashMap/"}]},{"title":"Java高并发程序设计第二章","slug":"Java高并发程序设计第二章","date":"2021-06-07T03:00:23.000Z","updated":"2022-06-13T15:00:55.975Z","comments":true,"path":"2021/06/07/Java高并发程序设计第二章/","link":"","permalink":"http://duanyushuai.github.io/2021/06/07/Java%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E7%AC%AC%E4%BA%8C%E7%AB%A0/","excerpt":"","text":"Java高并发程序设计第二章线程创建4个方法创建线程4个方法 继承Thread类创建线程 1234567public class MyThread extends Thread&#123;//继承Thread类 public void run()&#123; //重写run方法 &#125;&#125;new MyThread().start();//创建并启动线程 实现Runnable接口创建线程 12345678910111213141516public class MyThread2 implements Runnable &#123;//实现Runnable接口 public void run()&#123; //重写run方法 &#125;&#125;public class Main &#123; public static void main(String[] args)&#123; //创建并启动线程 MyThread2 myThread=new MyThread2(); Thread thread=new Thread(myThread); thread().start(); //或者 new Thread(new MyThread2()).start(); &#125;&#125; 使用Callable和Future创建线程 123456789101112131415public static void main(String[] args) &#123; // 先使用Lambda表达式创建Callable&lt;Integer&gt;对象 // 使用FutureTask来包装Callable对象 FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;((Callable&lt;Integer&gt;)() -&gt; 5); new Thread(task).start(); try &#123; System.out.println(&quot;子线程的返回值：&quot; + task.get()); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; 使用线程池例如用Executor框架 线程中断 禁止用stop()来退出线程，不安全。 线程安全退出，与中断有关的三个方法。 123public void Thread.interrupt() // 中断线程public boolean Thread.isInterrupted() // 判断是否被中断public static boolean Thread.interrupted() // 判断是否被中断，并清除当前中断状态 等待wait和通知notify 这两个⽅法并不是在Thread类中 的，⽽是输出Object类。 Object.wait()和Thread.sleep()方法都可以让线程等待若干时 间。除了wait()可以被唤醒外，另外一个主要区别就是wait()方法会 释放目标对象的锁，而Thread.sleep()方法不会释放任何资源。 等待线程结束（join)和谦让(yield)12345678910111213141516public class JoinMain &#123; public volatile static int i=0; public static class AddThread extends Thread&#123; @Override public void run() &#123; for(i=0;i&lt;1111111;i++); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AddThread at=new AddThread(); at.start(); at.join(); System.out.println(i); &#125;&#125; join()d的核心代码段 123while (isAlive()) &#123; wait(0);&#125; 可以看到，它让调⽤线程在当前线程对象上进⾏等待。当线程执 ⾏完成后，被等待的线程会在退出前调⽤notifyAll()通知所有的等待线 程继续执⾏。因此，值得注意的⼀点是：不要在应⽤程序中，在 Thread对象实例上使⽤类似wait()或者notify()等⽅法，因为这很有可能 会影响系统API的⼯作，或者被系统API所影响。 守护线程(Daemon)如垃圾回收线程 12345678910111213141516171819202122232425262728package testdemo;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class DaemonDemo &#123; private static final Logger logger = LoggerFactory.getLogger(DaemonDemo.class); public static class DaemonT extends Thread&#123; @Override public void run()&#123; while (true)&#123; logger.info(&quot;I am alive&quot;); try &#123; sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; DaemonT d = new DaemonT(); d.setDaemon(true); d.start(); &#125;&#125; d线程为main线程的守护线程，main一结束，d立即结束。 线程优先级设置1234Thread high=new HightPriority();LowPriority low=new LowPriority();high.setPriority(Thread.MAX_PRIORITY);low.setPriority(Thread.MIN_PRIORITY);","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"}]},{"title":"joda-time、日志、代码规范","slug":"joda-time  日志  代码规范","date":"2021-04-07T03:00:23.000Z","updated":"2022-06-13T15:02:06.174Z","comments":true,"path":"2021/04/07/joda-time  日志  代码规范/","link":"","permalink":"http://duanyushuai.github.io/2021/04/07/joda-time%20%20%E6%97%A5%E5%BF%97%20%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/","excerpt":"","text":"joda-time 日志 代码规范jode-time1234567891011121314@Test public void dateDemo()&#123; DateTime dt = new DateTime(2015,9,1,12,30,0); Date d = dt.toDate(); //当天起始日期 DateTime today = DateTime.now().withTimeAtStartOfDay(); //三天后的日期 DateTime dateTime = today.plusDays(3).plusMonths(1); //入住时间和离店时间的差值 DateTime checkIn = new DateTime(2015,8,29,0,0,0); DateTime checkOut = new DateTime(2015,9,2,0,0,0); System.out.println(Days.daysBetween(checkIn,checkOut).getDays()); &#125; 日期格式 123456789public class DateTimeExample1 &#123; private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormat.forPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); public static void main(String[] args) &#123; System.out.println(DATE_TIME_FORMATTER.print(new DateTime())); System.out.println(DATE_TIME_FORMATTER.parseDateTime(&quot;2000-01-01 12:12:12&quot;).toDate()); &#125;&#125; 日志规范配置 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 实例 123456789101112public class LogTest &#123; private static final Logger logger = LoggerFactory.getLogger(LogTest.class); public static void main(String[] args) &#123; logger.trace(&quot;log in trace level,args:&#123;&#125;&quot;,args); logger.debug(&quot;log in trace level,args:&#123;&#125;&quot;,args); logger.info(&quot;log in trace level,args:&#123;&#125;&quot;,args); logger.warn(&quot;log in trace level,args:&#123;&#125;&quot;,args); logger.error(&quot;log in trace level,args:&#123;&#125;&quot;,args); &#125;&#125; 查看日志 登录跳板机 在跳板机登录服务器 进入应用目录，一般为&#x2F;home&#x2F;q&#x2F;www&#x2F;&lt;应用名&gt;&#x2F; 该目录下有logs目录，其中存放了Tomcat日志，catalina.out记录了打印到控制台的日志，一般来说，查看改日志即可。 日志规范 禁止使用System.out.print() 在异常处理中打印关键信息 入参 关键变量值 注意数据保密 与用户相关的信息保密 打码到日志 不能影响正常业务 打印日志不能抛出异常，不能影响正常业务 日志影响性能，高QPS业务，控制日志输出量。 使用占位符代替字符串拼接 123456789public class LogTest &#123; private static final Logger logger = LoggerFactory.getLogger(LogTest.class); public static void main(String[] args) &#123; String s = &quot;111&quot;; logger.info(&quot;log in trace level,args: &#123;&#125;&quot;,args); logger.info(&quot;log in trace level,args: &#123;&#125; , &#123;&#125;&quot;,s,s.length()); &#125;&#125; 代码规范 代码给以后的自己看 强迫症 书《编写可读代码的艺术》 类名：形容词或动词 方法名：动词 注释 使用Javadoc格式编写注释 接口必须有注释，对参数，返回值有说明。例如参数限制，返回值是否为空，接口调用频率。","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"}]},{"title":"线程创建4个方法","slug":"线程创建4个方法","date":"2021-04-07T03:00:23.000Z","updated":"2022-06-13T15:00:03.170Z","comments":true,"path":"2021/04/07/线程创建4个方法/","link":"","permalink":"http://duanyushuai.github.io/2021/04/07/%E7%BA%BF%E7%A8%8B%E5%88%9B%E5%BB%BA4%E4%B8%AA%E6%96%B9%E6%B3%95/","excerpt":"","text":"线程创建4个方法创建线程4个方法 继承Thread类创建线程 1234567public class MyThread extends Thread&#123;//继承Thread类 public void run()&#123; //重写run方法 &#125;&#125;new MyThread().start();//创建并启动线程 实现Runnable接口创建线程 12345678910111213141516public class MyThread2 implements Runnable &#123;//实现Runnable接口 public void run()&#123; //重写run方法 &#125;&#125;public class Main &#123; public static void main(String[] args)&#123; //创建并启动线程 MyThread2 myThread=new MyThread2(); Thread thread=new Thread(myThread); thread().start(); //或者 new Thread(new MyThread2()).start(); &#125;&#125; 使用Callable和Future创建线程 123456789101112131415public static void main(String[] args) &#123; // 先使用Lambda表达式创建Callable&lt;Integer&gt;对象 // 使用FutureTask来包装Callable对象 FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;((Callable&lt;Integer&gt;)() -&gt; 5); new Thread(task).start(); try &#123; System.out.println(&quot;子线程的返回值：&quot; + task.get()); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; 使用线程池例如用Executor框架","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"}]},{"title":"CompletableFuture","slug":"CompletableFuture","date":"2021-04-05T03:00:23.000Z","updated":"2022-06-13T03:02:59.980Z","comments":true,"path":"2021/04/05/CompletableFuture/","link":"","permalink":"http://duanyushuai.github.io/2021/04/05/CompletableFuture/","excerpt":"","text":"CompletableFuture实例化12345public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier);public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor);public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable);public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor); supply:有返回结果 run：无返回结果 获取结果1234public T get()public T get(long timeout, TimeUnit unit)public T getNow(T valueIfAbsent)public T join() 计算完成后续操作1——complete1234public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable,? extends T&gt; fn) 方法1和2的区别在于是否使用异步处理，2和3的区别在于是否使用自定义的线程池，前三个方法都会提供一个返回结果和可抛出异常，我们可以使用lambda表达式的来接收这两个参数，然后自己处理。 方法4，接收一个可抛出的异常，且必须return一个返回值，类型与钻石表达式种的类型一样，详见下文的exceptionally() 例子1234567CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 10086; &#125;); future.whenComplete((result, error) -&gt; &#123; System.out.println(&quot;拨打&quot;+result); error.printStackTrace(); &#125;); whenCompleteAsync 与 whenComplete 区别 12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args) throws Exception &#123; CompletableFuture&lt;Integer&gt; f = new CompletableFuture&lt;Integer&gt;(); new Thread(() -&gt; &#123; // 子线程A启动 logger.info(&quot;子线程A启动&quot;); try &#123; logger.info(&quot;子线程A沉睡5s&quot;); Thread.sleep(5000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; logger.info(&quot;子线程A令future完成&quot;); f.complete(100); // 当子线程A执行到f.complete的时候，会去看是否有注册好的f的then或者when（非async的），如果有的话，会顺次去执行。 logger.info(&quot;子线程A结束&quot;); &#125;).start();; // 当前线程（主线程）执行到这里的时候，如果子线程还没有执行到f.complete(100)， // 那么当前线程会把whenComplete事件注册起来，并且说好哪个线程执行了f.complete(100)， // 哪个线程就负责执行whenComplete的内容。 // 如果当前线程（主线程）执行到这里的时候，f.complete(100)已经被其他线程执行完毕了。 // 那么只有当前线程自己来执行whenComplete里面的内容了。 f.whenCompleteAsync((i, ex) -&gt; &#123; // 这个场景下，whenComplete的回调的执行线程会是子线程A logger.info(&quot;do something after complete begin&quot;); try &#123; logger.info(&quot;沉睡10s&quot;); Thread.sleep(10000l); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; logger.info(&quot;do something after complete end&quot;); &#125;); logger.info(&quot;main over&quot;); System.in.read();&#125; 计算完成后续操作2——handle123public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T,Throwable,? extends U&gt; fn, Executor executor) 方法返回类型可以自定义","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"},{"name":"CompletableFuture","slug":"CompletableFuture","permalink":"http://duanyushuai.github.io/tags/CompletableFuture/"}]},{"title":"Jvisualvm","slug":"Jvisualvm","date":"2021-03-10T02:00:00.000Z","updated":"2022-07-24T13:18:06.389Z","comments":true,"path":"2021/03/10/Jvisualvm/","link":"","permalink":"http://duanyushuai.github.io/2021/03/10/Jvisualvm/","excerpt":"","text":"Jvisualvm下载https://visualvm.github.io/download.html 打开扩大字体打开bin 1visualvm.exe --fontsize 20 下载 visual GC 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。","categories":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"},{"name":"Jvisualvm","slug":"java/Jvisualvm","permalink":"http://duanyushuai.github.io/categories/java/Jvisualvm/"}],"tags":[{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"}]},{"title":"maven","slug":"maven_20220711_172008","date":"2021-03-09T02:00:00.000Z","updated":"2022-07-24T13:18:04.266Z","comments":true,"path":"2021/03/09/maven_20220711_172008/","link":"","permalink":"http://duanyushuai.github.io/2021/03/09/maven_20220711_172008/","excerpt":"","text":"mavenmaven 私服配置setting配置 项目 pom.xml配置maven私服访问地址因为maven默认会有一个下载地址，我们要重写下载地址，改写成自己的私服地址 如果需要打包到私服，需要配置打包私服相关参数 reository和mirror加载顺序1、在mirrorOf与repositoryId相同的时候优先是使用mirror的地址 2、mirrorOf等于*的时候覆盖所有repository配置 3、存在多个mirror配置的时候mirrorOf等于*放到最后 4、只配置mirrorOf为central的时候可以不用配置repository","categories":[{"name":"maven","slug":"maven","permalink":"http://duanyushuai.github.io/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://duanyushuai.github.io/tags/maven/"}]},{"title":"mysql中join的使用","slug":"mysql中join的使用","date":"2021-01-03T02:00:00.000Z","updated":"2022-06-26T10:39:21.188Z","comments":true,"path":"2021/01/03/mysql中join的使用/","link":"","permalink":"http://duanyushuai.github.io/2021/01/03/mysql%E4%B8%ADjoin%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"mysql 中join的使用","categories":[],"tags":[]},{"title":"基于胶囊网络的肽段预测","slug":"基于胶囊网络的肽段预测","date":"2020-09-10T02:00:21.000Z","updated":"2022-06-13T15:28:01.541Z","comments":true,"path":"2020/09/10/基于胶囊网络的肽段预测/","link":"","permalink":"http://duanyushuai.github.io/2020/09/10/%E5%9F%BA%E4%BA%8E%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C%E7%9A%84%E8%82%BD%E6%AE%B5%E9%A2%84%E6%B5%8B/","excerpt":"","text":"Prediction of Peptide Detectability Based on CapsNet and Convolutional Block Attention Modulehttps://www.mdpi.com/1422-0067/22/21/12080","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://duanyushuai.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://duanyushuai.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"python","slug":"python","permalink":"http://duanyushuai.github.io/tags/python/"},{"name":"深度学习","slug":"深度学习","permalink":"http://duanyushuai.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}],"categories":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/categories/JVM%E8%B0%83%E4%BC%98/"},{"name":"面试","slug":"面试","permalink":"http://duanyushuai.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"数据库","slug":"数据库","permalink":"http://duanyushuai.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"索引","slug":"索引","permalink":"http://duanyushuai.github.io/categories/%E7%B4%A2%E5%BC%95/"},{"name":"java各种变量","slug":"java各种变量","permalink":"http://duanyushuai.github.io/categories/java%E5%90%84%E7%A7%8D%E5%8F%98%E9%87%8F/"},{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/categories/docker/"},{"name":"msyql","slug":"msyql","permalink":"http://duanyushuai.github.io/categories/msyql/"},{"name":"开源框架学习","slug":"开源框架学习","permalink":"http://duanyushuai.github.io/categories/%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"},{"name":"线程","slug":"线程","permalink":"http://duanyushuai.github.io/categories/%E7%BA%BF%E7%A8%8B/"},{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/categories/springboot/"},{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/categories/java/"},{"name":"读书","slug":"读书","permalink":"http://duanyushuai.github.io/categories/%E8%AF%BB%E4%B9%A6/"},{"name":"redis","slug":"redis","permalink":"http://duanyushuai.github.io/categories/redis/"},{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/categories/java-web/"},{"name":"Guava","slug":"Guava","permalink":"http://duanyushuai.github.io/categories/Guava/"},{"name":"redis","slug":"Guava/redis","permalink":"http://duanyushuai.github.io/categories/Guava/redis/"},{"name":"算法","slug":"算法","permalink":"http://duanyushuai.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"谷粒商城","slug":"docker/谷粒商城","permalink":"http://duanyushuai.github.io/categories/docker/%E8%B0%B7%E7%B2%92%E5%95%86%E5%9F%8E/"},{"name":"工具","slug":"工具","permalink":"http://duanyushuai.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"http://duanyushuai.github.io/categories/rabbitMQ/"},{"name":"Jvisualvm","slug":"java/Jvisualvm","permalink":"http://duanyushuai.github.io/categories/java/Jvisualvm/"},{"name":"maven","slug":"maven","permalink":"http://duanyushuai.github.io/categories/maven/"},{"name":"深度学习","slug":"深度学习","permalink":"http://duanyushuai.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"JVM调优","slug":"JVM调优","permalink":"http://duanyushuai.github.io/tags/JVM%E8%B0%83%E4%BC%98/"},{"name":"面试","slug":"面试","permalink":"http://duanyushuai.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"数据库","slug":"数据库","permalink":"http://duanyushuai.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"索引","slug":"索引","permalink":"http://duanyushuai.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"java各种变量","slug":"java各种变量","permalink":"http://duanyushuai.github.io/tags/java%E5%90%84%E7%A7%8D%E5%8F%98%E9%87%8F/"},{"name":"docker","slug":"docker","permalink":"http://duanyushuai.github.io/tags/docker/"},{"name":"msyql","slug":"msyql","permalink":"http://duanyushuai.github.io/tags/msyql/"},{"name":"开源框架学习","slug":"开源框架学习","permalink":"http://duanyushuai.github.io/tags/%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"},{"name":"多线程","slug":"多线程","permalink":"http://duanyushuai.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"源码","slug":"源码","permalink":"http://duanyushuai.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"缓存","slug":"缓存","permalink":"http://duanyushuai.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"读书","slug":"读书","permalink":"http://duanyushuai.github.io/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"限流","slug":"限流","permalink":"http://duanyushuai.github.io/tags/%E9%99%90%E6%B5%81/"},{"name":"springboot","slug":"springboot","permalink":"http://duanyushuai.github.io/tags/springboot/"},{"name":"链表","slug":"链表","permalink":"http://duanyushuai.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"java web","slug":"java-web","permalink":"http://duanyushuai.github.io/tags/java-web/"},{"name":"Guava","slug":"Guava","permalink":"http://duanyushuai.github.io/tags/Guava/"},{"name":"redis","slug":"redis","permalink":"http://duanyushuai.github.io/tags/redis/"},{"name":"算法","slug":"算法","permalink":"http://duanyushuai.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"工具","slug":"工具","permalink":"http://duanyushuai.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"rabbitMQ","slug":"rabbitMQ","permalink":"http://duanyushuai.github.io/tags/rabbitMQ/"},{"name":"java","slug":"java","permalink":"http://duanyushuai.github.io/tags/java/"},{"name":"HashMap","slug":"HashMap","permalink":"http://duanyushuai.github.io/tags/HashMap/"},{"name":"CompletableFuture","slug":"CompletableFuture","permalink":"http://duanyushuai.github.io/tags/CompletableFuture/"},{"name":"maven","slug":"maven","permalink":"http://duanyushuai.github.io/tags/maven/"},{"name":"python","slug":"python","permalink":"http://duanyushuai.github.io/tags/python/"},{"name":"深度学习","slug":"深度学习","permalink":"http://duanyushuai.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}